{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ds_whole.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'glaucoma'}>,\n",
       "        <Axes: title={'center': 'age'}>,\n",
       "        <Axes: title={'center': 'ocular_pressure'}>],\n",
       "       [<Axes: title={'center': 'MD'}>, <Axes: title={'center': 'PSD'}>,\n",
       "        <Axes: title={'center': 'GHT'}>],\n",
       "       [<Axes: title={'center': 'cornea_thickness'}>,\n",
       "        <Axes: title={'center': 'RNFL4.mean'}>, <Axes: >]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGxCAYAAABIjE2TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABnj0lEQVR4nO3deVxTV/4//leEEBYBWYQQRUQHqxWKFhWlVlwKlrrUsR2t/bRFa1s7LtVRx2ptB7BWLbXWqbv9KGipSzvjOtoqblg/6BQdbd1rp7iDKKKgaAhwfn/4y/0aA5iEhNzA6/l45KE59+Tec25Obt6ce06OQgghQERERCQjjexdACIiIqJHMUAhIiIi2WGAQkRERLLDAIWIiIhkhwEKERERyQ4DFCIiIpIdBihEREQkOwxQiIiISHYYoBAREZHsMECxkZYtW2L48OH2LgYRUYMzfPhwtGzZ0t7FoFpigEJERESywwCFiIioBqWlpXVynHv37tXJcayloqICWq3WZvtngGKBzZs346mnnoJKpUKrVq3w97//HcnJyVAoFNW+5v79+5g0aRI6dOgAb29v+Pr6olu3bti8ebNBvvPnz0OhUCA9Pd1oHwqFAsnJyQZpZ86cwbBhwxAYGAiVSoUWLVrgjTfeMGg0J06cwIsvvggfHx+4urqiQ4cOWLVqlcF+9u3bB4VCgTVr1uD9999HUFAQGjdujAEDBuDatWsoKSnBO++8A39/f/j7+2PEiBG4c+eOwT4WLVqEHj16ICAgAB4eHoiIiEBqaip0Op2JZ5bqm99++w0jRoxAWFgY3N3d0axZMwwYMADHjx83ynvy5EnEx8fD3d0dTZs2xZgxY7Bt2zYoFArs27fPIO+uXbvQp08feHl5wd3dHc888wx2795dR7Uicx04cAB9+vSBp6cn3N3dERMTg23bthnkuXLlCt555x0EBwfDxcUFGo0GL7/8Mq5duwYASE9Ph0KhwPnz5w1ep792PdpGHmXq9alnz54IDw/H/v37ERMTA3d3d7z55psm1VP/PXD06FEMHjwYXl5e8Pb2xmuvvYbr168b5G3ZsiX69++PDRs2oGPHjnB1dUVKSgoAID8/H6NGjULz5s3h4uKC0NBQpKSkoLy83GAfS5YsQWRkJBo3bgxPT0+0bdsWH3zwgbS9tLQUkydPRmhoKFxdXeHr64tOnTph7dq1BvXt2bOnUV0evU2m/25KTU3FzJkzERoaCpVKhb179wIADh8+jIEDB8LX1xeurq7o2LEjvv32W5POW3Wca/XqBuiHH37A4MGD0aNHD6xfvx7l5eWYO3eu9CGqjlarxc2bNzF58mQ0a9YMZWVl2LVrFwYPHoy0tDS88cYbZpfl559/Rvfu3eHv748ZM2YgLCwMeXl52LJlC8rKyqBSqXD27FnExMQgICAAX375Jfz8/JCRkYHhw4fj2rVrmDJlisE+P/jgA/Tq1Qvp6ek4f/48Jk+ejGHDhsHZ2RmRkZFYu3Ytjh49ig8++ACenp748ssvpdf+97//xauvvorQ0FC4uLjg559/xieffIIzZ85g5cqVZtePHN/Vq1fh5+eHOXPmoGnTprh58yZWrVqF6OhoHD16FE888QQAIC8vD7GxsfDw8MCSJUsQEBCAtWvXYuzYsUb7zMjIwBtvvIEXX3wRq1atglKpxLJly9C3b1/s2LEDffr0qetqUg2ysrIQFxeHp556CitWrIBKpcLixYsxYMAArF27FkOHDsWVK1fQuXNn6HQ6fPDBB3jqqadQWFiIHTt2oKioCIGBgbUuhznXp7y8PLz22muYMmUKZs2ahUaNzPtb/o9//COGDBmCd999FydPnsRHH32EU6dO4d///jeUSqWU7z//+Q9Onz6NDz/8EKGhofDw8EB+fj66dOmCRo0a4W9/+xtat26NgwcPYubMmTh//jzS0tIAAOvWrcPo0aMxbtw4zJ07F40aNcJvv/2GU6dOSfufOHEivv76a8ycORMdO3bE3bt3ceLECRQWFlp8Hr/88ku0adMGc+fOhZeXF8LCwrB37148//zziI6OxtKlS+Ht7Y1169Zh6NChKC0ttXw8piCzdO7cWQQHBwutViullZSUCD8/P/Hw6QwJCRGJiYnV7qe8vFzodDoxcuRI0bFjRyk9NzdXABBpaWlGrwEgkpKSpOe9e/cWTZo0EQUFBdUe55VXXhEqlUpcvHjRID0hIUG4u7uLW7duCSGE2Lt3rwAgBgwYYJBvwoQJAoB47733DNIHDRokfH19qz1uRUWF0Ol0YvXq1cLJyUncvHmz2rzUcJSXl4uysjIRFhYm/vKXv0jpf/3rX4VCoRAnT540yN+3b18BQOzdu1cIIcTdu3eFr6+vUTutqKgQkZGRokuXLjavA5mna9euIiAgQJSUlEhp5eXlIjw8XDRv3lxUVlaKN998UyiVSnHq1Klq95OWliYAiNzcXIN0/bVL30aEECIxMVGEhIRUu6+ark+xsbECgNi9e7fZdU1KShIADNq2EEJ88803AoDIyMiQ0kJCQoSTk5M4e/asQd5Ro0aJxo0biwsXLhikz507VwCQPiNjx44VTZo0qbE84eHhYtCgQTXmiY2NFbGxsUbpj55D/XdT69atRVlZmUHetm3bio4dOwqdTmeQ3r9/fxEUFCQqKipqLEN1eIvHDHfv3sXhw4cxaNAguLi4SOn6WyGP89133+GZZ55B48aN4ezsDKVSiRUrVuD06dNml6W0tBRZWVkYMmQImjZtWm2+PXv2oE+fPggODjZIHz58OEpLS3Hw4EGD9P79+xs8b9euHQCgX79+Ruk3b940uM1z9OhRDBw4EH5+fnBycoJSqcQbb7yBiooK/Prrr2bXkRxfeXk5Zs2ahSeffBIuLi5wdnaGi4sLzp07Z9Dus7KyEB4ejieffNLg9cOGDTN4np2djZs3byIxMRHl5eXSo7KyEs8//zxycnJw9+7dOqkbPd7du3fx73//Gy+//DIaN24spTs5OeH111/H5cuXcfbsWXz//ffo1auXdL2xBXOuTz4+Pujdu7fFx/qf//kfg+dDhgyBs7OzdDtE76mnnkKbNm0M0v71r3+hV69e0Gg0Bm08ISEBwIPPCgB06dIFt27dwrBhw7B582bcuHHDqBxdunTB999/j6lTp2Lfvn1WGeMycOBAg16g3377DWfOnJHq/HCZX3jhBeTl5eHs2bMWHYsBihmKiooghKiyu/FxXZAbNmzAkCFD0KxZM2RkZODgwYPIycnBm2++ifv371tUloqKCjRv3rzGfIWFhQgKCjJK12g00vaH+fr6GjzXB2LVpevLfvHiRTz77LO4cuUK/v73v+PHH39ETk4OFi1aBMDxBn+RdUycOBEfffQRBg0ahK1bt+Lf//43cnJyEBkZadAmCgsLTfpc6W+lvvzyy1AqlQaPTz/9FEII3Lx507aVIpPpr5mPuwZdv379sdey2jD3+lRVec2hVqsNnjs7O8PPz8/oelvVca5du4atW7cate/27dsDgBSIvP7661i5ciUuXLiAl156CQEBAYiOjkZmZqa0ry+//BLvv/8+Nm3ahF69esHX1xeDBg3CuXPnLK7bo2XWfyYnT55sVObRo0cblNlcHINiBh8fHygUiirHm+Tn59f42oyMDISGhmL9+vUGg2kfHQHt6upaZXpVgYSTkxMuX75c43H9/PyQl5dnlH716lUAgL+/f42vN9WmTZtw9+5dbNiwASEhIVL6sWPHrLJ/ckz68SKzZs0ySL9x4waaNGkiPffz8zPpc6VvrwsWLEDXrl2rPKY1xiuQdfj4+KBRo0aPvQY1bdr0sdey6q6Npnz5mXt9qmnCgyny8/PRrFkz6Xl5eTkKCwvh5+f32OP4+/vjqaeewieffFLlvvWBHQCMGDECI0aMwN27d7F//34kJSWhf//++PXXXxESEgIPDw+kpKQgJSUF165dk3pTBgwYgDNnzgB4cF5v375tdJzqzuujZdZ/JqdNm4bBgwdX+Rr9WDNzsQfFDB4eHujUqRM2bdqEsrIyKf3OnTv417/+VeNrFQoFXFxcDN7c/Px8o1k8gYGBcHV1xS+//GKQ/mg+Nzc3xMbG4rvvvqvxA9qnTx/s2bNHuhjorV69Gu7u7tVe5M2lr5dKpZLShBD46quvrLJ/ckwKhcKgTQDAtm3bcOXKFYO02NhYnDhxwmCAH/BgIODDnnnmGTRp0gSnTp1Cp06dqnw8fPuV7MvDwwPR0dHYsGGDQS9FZWUlMjIy0Lx5c7Rp0wYJCQnYu3dvjbcC9DNKHr02btmy5bHlqOvr0zfffGPw/Ntvv0V5eXmVs2Ue1b9/f5w4cQKtW7eusn0/HKDoeXh4ICEhAdOnT0dZWRlOnjxplCcwMBDDhw/HsGHDcPbsWWnqdMuWLfHrr78aBH6FhYXIzs42qa5PPPEEwsLC8PPPP1f7mfT09DRpX49iD4qZZsyYgX79+qFv374YP348Kioq8Nlnn6Fx48Y1di3rp5ONHj0aL7/8Mi5duoSPP/4YQUFBBt1tCoUCr732GlauXInWrVsjMjISP/30E9asWWO0z3nz5qF79+6Ijo7G1KlT8Yc//AHXrl3Dli1bsGzZMnh6eiIpKUm6p/m3v/0Nvr6++Oabb7Bt2zakpqbC29vbKuclLi4OLi4uGDZsGKZMmYL79+9jyZIlKCoqssr+yTH1798f6enpaNu2LZ566ikcOXIEn332mVF3/oQJE7By5UokJCRgxowZCAwMxJo1a6S/8vSzKBo3bowFCxYgMTERN2/exMsvv4yAgABcv34dP//8M65fv44lS5bUeT2perNnz0ZcXBx69eqFyZMnw8XFBYsXL8aJEyewdu1aKBQKzJgxA99//z169OiBDz74ABEREbh16xZ++OEHTJw4EW3btkXnzp3xxBNPYPLkySgvL4ePjw82btyIAwcOPLYMdX192rBhA5ydnREXFyfN4omMjMSQIUMe+9oZM2YgMzMTMTExeO+99/DEE0/g/v37OH/+PLZv346lS5eiefPmePvtt+Hm5oZnnnkGQUFByM/Px+zZs+Ht7Y3OnTsDAKKjo9G/f3889dRT8PHxwenTp/H111+jW7ducHd3B/DgVtGyZcvw2muv4e2330ZhYSFSU1Ph5eVlcn2XLVuGhIQE9O3bF8OHD0ezZs1w8+ZNnD59Gv/5z3/w3XffWXYiLRpa28Bt3LhRRERECBcXF9GiRQsxZ84c8d577wkfHx8pT1WzeObMmSNatmwpVCqVaNeunfjqq6+kUd8Pu337tnjrrbdEYGCg8PDwEAMGDBDnz583msUjhBCnTp0Sf/rTn4Sfn59UnuHDh4v79+9LeY4fPy4GDBggvL29hYuLi4iMjDSaJaQfCf/dd98ZpOtHzufk5Bik68t9/fp1KW3r1q0iMjJSuLq6imbNmom//vWv4vvvvzcaYU8NR1FRkRg5cqQICAgQ7u7uonv37uLHH3+scubAiRMnxHPPPSdcXV2Fr6+vGDlypFi1apUAIH7++WeDvFlZWaJfv37C19dXKJVK0axZM9GvXz+j9kvy8OOPP4revXsLDw8P4ebmJrp27Sq2bt1qkOfSpUvizTffFGq1WiiVSqHRaMSQIUPEtWvXpDy//vqriI+PF15eXqJp06Zi3LhxYtu2bSbN4jH1+hQbGyvat29vUT3118UjR46IAQMGiMaNGwtPT08xbNgwg3oI8eA7ol+/flXu5/r16+K9994ToaGhQqlUCl9fXxEVFSWmT58u7ty5I4QQYtWqVaJXr14iMDBQuLi4SOfrl19+kfYzdepU0alTJ+Hj4yNUKpVo1aqV+Mtf/iJu3LhhcLxVq1aJdu3aCVdXV/Hkk0+K9evXVzuL57PPPquyzD///LMYMmSICAgIEEqlUqjVatG7d2+xdOlSS06lEEIIhRBCWBbakJ5Op0OHDh3QrFkz7Ny5097FIao33nnnHaxduxaFhYW8dUOyl5ycjJSUFFy/ft1q4/saMt7iscDIkSMRFxcndastXboUp0+fxt///nd7F43IYc2YMQMajQatWrWSxnX97//+Lz788EMGJ0QNEAMUC5SUlGDy5Mm4fv06lEolnn76aWzfvh3PPfecvYtG5LCUSiU+++wzXL58GeXl5QgLC8O8efMwfvx4exeNGrjKykpUVlbWmMfZmV+n1sZbPERERDXQ37qpSW5ursHaNVR7DFCIiIhqcPXqVaOfanjUU089xVuRVsYAhYiIiGSHP9RGREREsuOQo3oqKytx9epVeHp61vonian+EkKgpKQEGo3G7OXS6wrbMpnCEdoywPZMj2dOW3bIAOXq1atGq/MSVefSpUs2XYisNtiWyRxybssA2zOZzpS27JABiv53/S9dumT0c7w6nQ47d+5EfHy8wZLQ9V1DrTdQfd2Li4sRHBxs8ToQdaGmtlyX5Nx+5Fw2oG7K5whtGZBPezaF3NtVbci5bua0ZYcMUPRdh15eXlUGKO7u7vDy8pLdG2NLDbXewOPrLueu5pracl2Sc/uRc9mAui2fnNsyIJ/2bAq5t6vacIS6mdKW5Xszk4iIiBosBihEREQkOw55i4fqt5ZTt5mVX+UkkNrFRoUhh2Fuuzk/p5+NSkLWYO77CfA9rW/Yg0JERESywwCFiIiIZIcBCjVY+/fvx4ABA6DRaKBQKLBp0yaD7UIIJCcnQ6PRwM3NDT179sTJkycN8mi1WowbNw7+/v7w8PDAwIEDcfny5TqsBRFR/cQAhRqsu3fvIjIyEgsXLqxye2pqKubNm4eFCxciJycHarUacXFxKCkpkfJMmDABGzduxLp163DgwAHcuXMH/fv3R0VFRV1Vg4ioXuIgWWqwEhISkJCQUOU2IQTmz5+P6dOnY/DgwQCAVatWITAwEGvWrMGoUaNw+/ZtrFixAl9//TWee+45AEBGRgaCg4Oxa9cu9O3bt87qQkRU3zBAIapCbm4u8vPzER8fL6WpVCrExsYiOzsbo0aNwpEjR6DT6QzyaDQahIeHIzs7u8oARavVQqvVSs+Li4sBPPhhJZ1OZ8Ma1Ux/bHuWoTqmlk3lZN7C7Naqa12cOzm+L0S2xgCFqAr5+fkAgMDAQIP0wMBAXLhwQcrj4uICHx8fozz61z9q9uzZSElJMUrfuXMn3N3drVH0WsnMzLR3Ear1uLKZO9V8+/bttSiNMVueu9LSUpvtm0iuGKAQ1eDRn2MWQjz2J5pryjNt2jRMnDhReq5flyI+Pt7uP3WfmZmJuLg42f00tqllC0/eYdZ+TyRb5xZcXZw7fU8bUUPCAIWoCmq1GsCDXpKgoCApvaCgQOpVUavVKCsrQ1FRkUEvSkFBAWJiYqrcr0qlgkqlMkpXKpWyCAzkUo6qPK5s2grz1qmxdj1tee7k+p4Q2RJn8RBVITQ0FGq12qDbvqysDFlZWVLwERUVBaVSaZAnLy8PJ06cqDZAISIi07AHhRqsO3fu4LfffpOe5+bm4tixY/D19UWLFi0wYcIEzJo1C2FhYQgLC8OsWbPg7u6OV199FQDg7e2NkSNHYtKkSfDz84Ovry8mT56MiIgIaVYPERFZhgEKNViHDx9Gr169pOf6sSGJiYlIT0/HlClTcO/ePYwePRpFRUWIjo7Gzp074enpKb3miy++gLOzM4YMGYJ79+6hT58+SE9Ph5OTU53Xh4ioPmGAQg1Wz549IUT1U1MVCgWSk5ORnJxcbR5XV1csWLAACxYssEEJiYgaLo5BISIiItlhDwoRyU7Lqduk/6ucBFK7PJhGbO5MHSJyXOxBISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2GKAQERGR7DBAISIiItnhL8kSUYP08K/Vmur8nH42KAkRVYU9KERERCQ7DFCIiIhIdswKUGbPno3OnTvD09MTAQEBGDRoEM6ePWuQRwiB5ORkaDQauLm5oWfPnjh58qRBHq1Wi3HjxsHf3x8eHh4YOHAgLl++XPvaEBERUb1gVoCSlZWFMWPG4NChQ8jMzER5eTni4+Nx9+5dKU9qairmzZuHhQsXIicnB2q1GnFxcSgpKZHyTJgwARs3bsS6detw4MAB3LlzB/3790dFRYX1akZEREQOy6xBsj/88IPB87S0NAQEBODIkSPo0aMHhBCYP38+pk+fjsGDBwMAVq1ahcDAQKxZswajRo3C7du3sWLFCnz99dd47rnnAAAZGRkIDg7Grl270LdvXytVjYiIiBxVrWbx3L59GwDg6+sLAMjNzUV+fj7i4+OlPCqVCrGxscjOzsaoUaNw5MgR6HQ6gzwajQbh4eHIzs6uMkDRarXQarXS8+LiYgCATqeDTqczyKt/HjXjB2grFSbV40Sy4wdF+no/ej4ckcpJmJe/0YP81bUFImoYzJmZpXISSO1iw8JQrVkcoAghMHHiRHTv3h3h4eEAgPz8fABAYGCgQd7AwEBcuHBByuPi4gIfHx+jPPrXP2r27NlISUkxSt+5cyfc3d2rfM3HnSpNrsv27dtNzit3mZmZ9i5CrVl60Xi07qWlpVYoDdH/U9UXoP6LLjx5B7QVhn8UcVoykeUsDlDGjh2LX375BQcOHDDaplAYfkiFEEZpj6opz7Rp0zBx4kTpeXFxMYKDgxEfHw8vLy+DvDqdDpmZmfjocKMG14OSmZmJuLg4KJVKexenVsKTd5iVX9VI4ONOlUZ11/e0ERGR47EoQBk3bhy2bNmC/fv3o3nz5lK6Wq0G8KCXJCgoSEovKCiQelXUajXKyspQVFRk0ItSUFCAmJiYKo+nUqmgUqmM0pVKZbVfxtpKhdFfM9Vx9C/0h9V0ThyFqe/box6tu6OfByKihsysWTxCCIwdOxYbNmzAnj17EBoaarA9NDQUarXaoKu9rKwMWVlZUvARFRUFpVJpkCcvLw8nTpyoNkAhIiKihsWsHpQxY8ZgzZo12Lx5Mzw9PaUxI97e3nBzc4NCocCECRMwa9YshIWFISwsDLNmzYK7uzteffVVKe/IkSMxadIk+Pn5wdfXF5MnT0ZERIQ0q4eIiIgaNrMClCVLlgAAevbsaZCelpaG4cOHAwCmTJmCe/fuYfTo0SgqKkJ0dDR27twJT09PKf8XX3wBZ2dnDBkyBPfu3UOfPn2Qnp4OJyen2tWGiIiI6gWzAhQhHj/9U6FQIDk5GcnJydXmcXV1xYIFC7BgwQJzDk9EDsqShfmIqGHjWjxEREQkOwxQiIiISHYYoBAREZHsMEAhInJw+/fvx4ABA6DRaKBQKLBp0yaD7VxlnhwRAxQiIgd39+5dREZGYuHChVVu5yrz5IhqtVggERHZX0JCAhISEqrcxlXmyVExQCEiqsdstco8YN5K8+Yyd1Vzs/dfzSro9YGcV7c3p0wMUIiI6jFbrTIPWLbSvKksXdXcXPVhBfjqyLFu5qwyzwCFiKgBsPYq84B5K82by9xVzc1V3Sro9YGcV7c3Z5V5BihE1UhOTjb66/DhvyiFEEhJScHy5culZR0WLVqE9u3b26O4RFWy1SrzgGUrzZvK0lXNzVUfVoCvjhzrZk55OIuHqAbt27dHXl6e9Dh+/Li0zZSZEUT2xlXmyVGxB4WoBs7OztJfoA8zZWYEUV25c+cOfvvtN+l5bm4ujh07Bl9fX7Ro0YKrzJNDYoBCVINz585Bo9FApVIhOjoas2bNQqtWrUyaGVEVW856qA1bj/qvzYwM/WwL/b9yU1P5rHU+H7efw4cPo1evXtJz/biQxMREpKenc5V5ckgMUIiqER0djdWrV6NNmza4du0aZs6ciZiYGJw8edKkmRFVseWsB2uw1ah/a8zI+LhTZe13YkNVlW/79u1W2ffjZj707NmzxtXmuco8OSIGKETVePiHryIiItCtWze0bt0aq1atQteuXQGYPzPClrMeasPWo/5rMyNDP9vio8ONoK2sm4GT5qipfCeSrfMDZ+bMfCCqLxigEJnIw8MDEREROHfuHAYNGgSg5pkRVbHlrAdrsFU5rDEjQ1upqLOZHZaoqnzWOpdyaBtEdY2zeIhMpNVqcfr0aQQFBZk0M4KIiCzHHhSiakyePBkDBgxAixYtUFBQgJkzZ6K4uBiJiYlQKBSPnRlBRESWY4BCVI3Lly9j2LBhuHHjBpo2bYquXbvi0KFDCAkJAQCTZkYQEZFlGKAQVWPdunU1bjdlZgQREVmGAQoREdlcy6nb7F0EcjAcJEtERESywwCFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2GKAQERGR7DBAISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2nO1dACIiInsJT94BbYXC5Pzn5/SzYWnoYexBISIiItlhDwoRmaXl1G32LgIRNQAMUIiIbMSSYI63EIge4C0eIiIikh32oBA1cC2nboPKSSC1i/kDBomIbIU9KERERCQ7DFCIiIhIdniLh4iIyETmDnzmoGfLsQeFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2OIuHqB7hOjlEVF8wQCEiIrIRrsdkOd7iISIiItlhgEJERESyw1s8RDLGMSVE1FDZtQdl8eLFCA0NhaurK6KiovDjjz/aszhEFmNbpvqCbdkxtZy6TXqEJ+8A8GB18ofTH344ArsFKOvXr8eECRMwffp0HD16FM8++ywSEhJw8eJFexWJyCJsy1RfsC2TnNjtFs+8efMwcuRIvPXWWwCA+fPnY8eOHViyZAlmz55tr2IRmY1tmeoLtmV5cJQeDluzS4BSVlaGI0eOYOrUqQbp8fHxyM7ONsqv1Wqh1Wql57dv3wYA3Lx5EzqdziCvTqdDaWkpnHWNUFGpMKk8hYWF5lZBdvT1LiwshFKptHdxasW5/K55+SsFSksrjepeUlICABBCWLV8D7NlWwbMPxeW0p9Dcz43dUXOZQOsX76qrkdybMuAee25rtqyqeTermrDlLrZ63vPrLYs7ODKlSsCgPi///s/g/RPPvlEtGnTxih/UlKSAMAHHxY9Ll26xLbMR714yKktsz3zUZuHKW3ZrrN4FArDyE4IYZQGANOmTcPEiROl55WVlbh58yb8/PyM8hcXFyM4OBiXLl2Cl5eXbQouQw213kD1dRdCoKSkBBqNxuZlsEVbrktybj9yLhtQN+WTY1sG5NueTSH3dlUbcq6bOW3ZLgGKv78/nJyckJ+fb5BeUFCAwMBAo/wqlQoqlcogrUmTJjUew8vLS3ZvTF1oqPUGqq67t7e3TY9ZF225Lsm5/ci5bIDtyye3tgzIvz2bQu7tqjbkWjdT27JdZvG4uLggKioKmZmZBumZmZmIiYmxR5GILMK2TPUF2zLJjd1u8UycOBGvv/46OnXqhG7dumH58uW4ePEi3n33XXsVicgibMtUX7Atk5zYLUAZOnQoCgsLMWPGDOTl5SE8PBzbt29HSEhIrfarUqmQlJRk1O1Y3zXUegP2r7ut2nJdsvc5rImcywbIv3zmqA9t2VT16X17VH2pm0IIG85bIyIiIrIAFwskIiIi2WGAQkRERLLDAIWIiIhkhwEKERERyQ4DFBlLT0+HQqGAQqHAvn37jLYLIfCHP/wBCoUCPXv2lNL1r1EoFHBycoKPjw8iIyMxatQoHDp0qO4qQA3aw+1XoVDA2dkZzZs3x4gRI3DlyhUp3+nTp/H666+jVatWcHV1hb+/P55++mmMHTsWxcXFUr7hw4cb7M/DwwMtW7bEwIEDkZaWZrAmDJEt/PLLLxg5ciRat24NNzc3uLm5ISwsDKNGjcLhw4elfMnJyVAoFLhx40aV+wkPD5eu2Y+26+oew4cPr4MayovDBSiLFy9GaGgoXF1dERUVhR9//LHG/FlZWYiKioKrqytatWqFpUuX1lFJrcfT0xMrVqwwqvuCBQvw3//+F56enkaviY2NBfDgp6dv3bqFX375BcuXL0e3bt0wfvz4uq6Cxfbv348BAwZAo9FAoVBg06ZNj31NfXjPbWH27Nno3LkzPD09ERAQgEGDBuHs2bMGeaq6WHbt2rVWx01LS8PBgweRmZmJt99+G2vXrsWzzz6Lu3fv4ujRo4iKisLu3buRm5sLrVaLwsJCHD16FEuXLsXNmzcBPAjGjx07BuDBD4p17NgRCxcuxIwZM+Dh4YG3334bUVFRuHz5cq3KWp2WLVtW+aUxZswYALY5b1R71mzzy5YtQ1RUFP79739j/Pjx+Ne//oVt27ZhwoQJOHnyJDp37oz//ve/Zpfxo48+wsGDB6XHokWLAACzZs0ySP/oo48MXqcPgh5+qNVqabsQAsnJydBoNHBzc0PPnj1x8uRJs8tnV5YvLVX31q1bJ5RKpfjqq6/EqVOnxPjx44WHh4e4cOFClfl///134e7uLsaPHy9OnTolvvrqK6FUKsU//vGPOi65ZdLS0gQA8dZbbwkXFxfh7OxsUHcnJyfx9NNPi/bt24vY2FjpdQDEoEGDBABx9uxZkZeXJ/Ly8sTly5fFiBEjBACxePFi+1XMDNu3bxfTp08X//znPwUAsXHjxhrzO/p7bkt9+/YVaWlp4sSJE+LYsWOiX79+okWLFuLOnTtSnsTERPH8889LbSYvL08UFhZadDx9+83JyTFI/+ijjwQAkZGRId544w3h4eEhpk6dKtq3b29w3IKCAlFZWSmEEGLOnDnC2dlZuLq6iuPHj4uhQ4eKoKAgUVxcLIQQYseOHUKpVIro6GgLz07NCgoKDMqWmZkpAIi9e/cKIax73sh6rNXmDxw4IBo1aiQGDBggtFptlcf69ttvxZUrV4QQ/28RxevXr1eZ99Fr9sP27t0rAIjvvvuuxrolJSVV+ZnRmzNnjvD09BT//Oc/q/zMOAKHClC6dOki3n33XYO0tm3biqlTp1aZf8qUKaJt27YGaaNGjRJdu3a1WRmtSX+B3717t2jUqJHo0aOHtO3WrVtCoVCIhISEGgOUoqIig32WlpYKf39/ERoaWke1sB5TAhRHf8/rUkFBgQAgsrKypLTExETx4osvWmX/1QUo27ZtEwDEJ598Ivr16yeCgoLE3/72NxEZGVnlfiorK4VarRZPP/208PDwEEIIcf/+feHt7S2WLl0q5Rs9erRRfWxl/PjxonXr1lIAZc3zRrZjaZt/4YUXhFKpFFevXjXpOHUVoDzuMzNnzhwprarPjNw5zC2esrIyHDlyBPHx8Qbp8fHxyM7OrvI1Bw8eNMrft29fHD58GDqdzmZltTY3NzcIIZCXlyelrV27Fs7Ozrh9+3aNr+3YsSOCgoLQp08f7N27F25ubnjuueeQm5trs+5we6ov73ld0LcdX19fg/R9+/YhICAAbdq0wdtvv42CggKrHve3334DADRt2hTdunVDXl4eNmzYgDNnziAoKAihoaF45ZVX8PvvvwMAcnNzkZ+fj2bNmkn7UKlUiI2NNfjsDxw4EMCD24K2VFZWhoyMDLz55psGK/ba+rxR7VnS5isqKrB371506tQJQUFBZh2voqIC5eXlRg9rOXfuHDQaTbWfmYevhVV9ZuTOYQKUGzduoKKiwmhVzcDAQKPVN/Xy8/OrzF9eXl7t4CU5unXrFoQQOHfunHQPceXKlYiIiKi2Hu7u7li+fDn++c9/YsOGDXjiiSfQp08f7N+/X/rZ6qtXr9ZZHepKfXnPbU0IgYkTJ6J79+4IDw+X0hMSEvDNN99gz549+Pzzz5GTk4PevXvXagCq/iJ9584dbNu2DTNnzoSnpycGDhyIyZMnY9CgQThx4gS0Wi2uX78OZ2dnHDx4EF27dkVhYaH0+XZ1dTXY76Of/bpq15s2bcKtW7cMBi3a4ryRdVna5m/cuIF79+5V+XP/jwYg4pEfZler1VAqlUYPa4wFiY6OxurVq7Fjxw589dVXyM/PR0xMjMFnxpzvSzmy21o8lnr4LxbgQaN7NO1x+atKdwTNmjXDypUrMXz4cOTk5OCtt96qdpCwj48P3n77bel5t27dcOnSJcydOxft2rWrqyLbRX16z21l7Nix+OWXX3DgwAGD9KFDh0r/Dw8PR6dOnRASEoJt27Zh8ODBFh3r0QGHERERWLJkiXTx3LhxI06fPo0dO3bg8OHDyMrKwuXLl6FQKPDZZ59JPSOP++w/+uVgKytWrEBCQgI0Go2UZovzRtZlizYfFRWFn3/+WXr+2WefYfLkydLzXbt2wdvb2+h1r7zyiqXVkCQkJEj/j4iIQLdu3dC6dWusWrVK+syZ+30pNw4ToPj7+8PJycko+isoKDCKEvXUanWV+Z2dneHn52ezslpbkyZN4OTkhNjYWGRkZOD+/fto06YN3N3dERgYiMLCQpP207VrV2RkZMDd3R0ADC6w9UV9ec9tady4cdiyZQv279+P5s2b15g3KCgIISEhOHfunMXHW716Ndq1awdnZ2cEBgZW2U3erl07KXAWQmD+/PmYOHEivvvuO7zzzjsAgHv37hm85tHP/oULFwDYtl1fuHABu3btwoYNG2rMZ43zRtZTmzbv7+8PNzc3qX09bM2aNSgtLUVeXp4USD8sMjIS/v7+RumP9gZag4eHByIiInDu3DkMGjQIwIMe5Yc/bzV9X8qRw9zicXFxQVRUFDIzMw3SMzMzERMTU+VrunXrZpR/586d6NSpE5RKpc3Kam1KpRJRUVFwcnLCjRs3sHTpUowYMaLGulfl6NGjCAgIwK5du9C6devHflAdUX15z21BCIGxY8diw4YN2LNnD0JDQx/7msLCQly6dMnse+8Pa9euHTp16oQOHTqYtB+FQoHRo0dDoVCgpKQEoaGhUKvVBrduysrKkJWVZdD+t2zZAgAGvwlkbWlpaQgICEC/fv1qzGeN80a1Z4027+TkhN69e+Pw4cMG4wAB4Mknn0SnTp0QERFhk/KbQ6vV4vTp09I4LrVabXAtrOozI3v2GJlrKf004xUrVohTp06JCRMmCA8PD3H+/HkhhBBTp04Vr7/+upRfP+X0L3/5izh16pRYsWKFQ005fXgWhL7uCQkJonfv3uLtt9+W6t6+fXsRHBws1R2A6N69u9i4caP49ddfxYkTJ8TUqVMFANG7d28BQCxfvtzOtTNNSUmJOHr0qDh69KgAIObNmyeOHj0qTS2vb++5Lf35z38W3t7eYt++fQZTE0tLS4UQD871pEmTRHZ2tsjNzRV79+4V3bp1E82aNbNoamJ1s3gepp8VMWnSJLFv3z7x+++/i0OHDonnnntOABDPPPOMEOLBlEmlUilNMx42bJjBlMmdO3cKpVIpYmJizC6nqSoqKkSLFi3E+++/b5Bu7fNG1mOtNq+fZjxw4EBRVlZmdJzc3FwBQHz22WdCiLqZxfPoZ6Z///7C09NT+j6cM2eO8Pb2Fhs2bKjyM+MIHCpAEUKIRYsWiZCQEOHi4iKefvppo+lij77p+/btEx07dhQuLi6iZcuWYsmSJXVcYss9eoGvru7t27cXgYGBUt0BiIiICNGsWTPh4uIiGjduLEJDQ0VoaKgAIP7yl7/Yq0pm039YH30kJiYKIerfe25LVZ1HACItLU0I8WAKenx8vGjatKlQKpWiRYsWIjExUVy8eNGi45kSoPTv3190795ddOjQQfj6+gonJyfh7e0tGjduLJydncXOnTuFEA+mTUZGRgoAQqlUig4dOoiVK1eK1atXi2HDhgknJycRHh4uLl++bFFZTbFjxw7pt4UeZu3zRtZjzTa/ZMkS4ezsLMLDw8WXX34pdu/eLfbu3SvWrFkjXnrpJQFALFu2TAhRNwGK/ndNlEql0Gg0YvDgweLkyZPS9srKSpGUlCTUarVQqVSiR48e4vjx4yacNflwuAClITHlAi+EcWN/+IPYqFEj4eXlJSIiIsQ777wjDh48aONSEz1gSvvdsWOHePPNN8WTTz4pvL29hbOzswgKChKDBw82aquJiYkGbdvNzU20aNFCDBgwQKxcubLaH9AispZjx46JESNGiNDQUKFSqYSrq6v4wx/+IN544w2xe/duKV9dBCgNgUKIOhr6TkRERGQihxkkS0RERA0HAxQiIiKSHQYoREREJDsMUIiIiEh2GKAQERGR7DBAISIiItlxmLV4HlZZWYmrV6/C09PToRY+orolhEBJSQk0Gg0aNZJnLM62TKZwhLYMsD3T45nTlh0yQLl69SqCg4PtXQxyEJcuXZLtukNsy2QOObdlgO2ZTGdKW3bIAMXT0xPAgwp6eXlZZZ86nQ47d+5EfHy8Qy4qx/IbKy4uRnBwsNRe5MgabdnR33trqq/nwhHaMlB9e66v78vjNNR6A9XX3Zy27JABir7r0MvLy6oBiru7O7y8vByyIbH81ZNzV7M12rKjv/fWVN/PhZzbMlB9e67v70t1Gmq9gcfX3ZS2LN+bmURERNRgMUAhIiIi2XHIWzwNRcup20zOq3ISSO1iw8KQQzCnzVjq/Jx+Nj8GEclPXX8nsQeFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2GKAQERGR7DBAISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2GKAQERGR7DBAISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2zApQZs+ejc6dO8PT0xMBAQEYNGgQzp49a5BHCIHk5GRoNBq4ubmhZ8+eOHnypEEerVaLcePGwd/fHx4eHhg4cCAuX75c+9oQERFRvWBWgJKVlYUxY8bg0KFDyMzMRHl5OeLj43H37l0pT2pqKubNm4eFCxciJycHarUacXFxKCkpkfJMmDABGzduxLp163DgwAHcuXMH/fv3R0VFhfVqRkRERA7LrADlhx9+wPDhw9G+fXtERkYiLS0NFy9exJEjRwA86D2ZP38+pk+fjsGDByM8PByrVq1CaWkp1qxZAwC4ffs2VqxYgc8//xzPPfccOnbsiIyMDBw/fhy7du2yfg2JqrF//34MGDAAGo0GCoUCmzZtMtjO3kAiIvtxrs2Lb9++DQDw9fUFAOTm5iI/Px/x8fFSHpVKhdjYWGRnZ2PUqFE4cuQIdDqdQR6NRoPw8HBkZ2ejb9++RsfRarXQarXS8+LiYgCATqeDTqerTRUk+v1Ya3/WoHISpudt9CCvnMpvDluc/8ft6+7du4iMjMSIESPw0ksvGW3X9wamp6ejTZs2mDlzJuLi4nD27Fl4enoCeNAbuHXrVqxbtw5+fn6YNGkS+vfvjyNHjsDJyclqdSEiamgsDlCEEJg4cSK6d++O8PBwAEB+fj4AIDAw0CBvYGAgLly4IOVxcXGBj4+PUR796x81e/ZspKSkGKXv3LkT7u7ullahSpmZmVbdX22kdjH/NXIqvyWsWf7S0tIatyckJCAhIaHKbY/2BgLAqlWrEBgYiDVr1mDUqFFSb+DXX3+N5557DgCQkZGB4OBg7Nq1q86C7YeDO3OCWkvJOQiW4x8a1lDf6kNkCosDlLFjx+KXX37BgQMHjLYpFAqD50IIo7RH1ZRn2rRpmDhxovS8uLgYwcHBiI+Ph5eXlwWlN6bT6ZCZmYm4uDgolUqr7LO2wpN3mJxX1Ujg406Vsiq/OWxx/vVf/pawVW+gLYPtzMxMi4Jac23fvt32B6klRw/UH1VTsD179mxs2LABZ86cgZubG2JiYvDpp5/iiSeekPIIIZCSkoLly5ejqKgI0dHRWLRoEdq3by/l0Wq1mDx5MtauXYt79+6hT58+WLx4MZo3b27TuhFVx6IAZdy4cdiyZQv2799v0HjVajWAB70kQUFBUnpBQYHUq6JWq1FWVoaioiKDXpSCggLExMRUeTyVSgWVSmWUrlQqrf5lbIt9WkpbUXNQVxU5ld8S1ix/bfZjq95AWwTbDwd3HT/ZY9E+zHEi2Tjwkgs5/qFhDTUF2/rJC507d0Z5eTmmT5+O+Ph4nDp1Ch4eHgB4u5Ick1kBihAC48aNw8aNG7Fv3z6EhoYabA8NDYVarUZmZiY6duwIACgrK0NWVhY+/fRTAEBUVBSUSiUyMzMxZMgQAEBeXh5OnDiB1NRUa9SJyGqs3Rtoy2BbqVRaFNRachy5c/RA/VE11eWHH34weJ6WloaAgAAcOXIEPXr0sNntSiJbMytAGTNmDNasWYPNmzfD09NT+ivR29sbbm5uUCgUmDBhAmbNmoWwsDCEhYVh1qxZcHd3x6uvvirlHTlyJCZNmgQ/Pz/4+vpi8uTJiIiIkD4YRPZmq95AIlurq8kLgOljqurr2KDHqW/1tsbEDXPOhVkBypIlSwAAPXv2NEhPS0vD8OHDAQBTpkzBvXv3MHr0aOle586dO6VuRAD44osv4OzsjCFDhkj3OtPT09mNSLLB3kByRHU5eQEwf0xVfRsbZKr6Um9rTNx43OSFh5l9i+dxFAoFkpOTkZycXG0eV1dXLFiwAAsWLDDn8ERWdefOHfz222/S89zcXBw7dgy+vr5o0aIFewPJ4dTl5AXA9DFV9XVs0OPUt3pbY+KGOZMXavU7KESO7PDhw+jVq5f0XH+hTUxMRHp6OnsDyaHU9eQFwPwxVfVtbJCp6ku9rTFxw5zzwMUCqcHq2bMnhBBGj/T0dAD/rzcwLy8P9+/fR1ZWltRtrqfvDSwsLERpaSm2bt2K4OBgO9SGGiohBMaOHYsNGzZgz549NU5e0NPfrtQHHw/frtTT367keCqyF/agEBE5ME5eoPqKAQoRkQPj5AWqrxigEBE5ME5eoPqKY1CIiIhIdhigEBERkewwQCEiIiLZ4RgUIiKqE+HJO0z+LY3zc/rZuDQkd+xBISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2GKAQERGR7DBAISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2GKAQERGR7Dib+4L9+/fjs88+w5EjR5CXl4eNGzdi0KBB0nYhBFJSUrB8+XIUFRUhOjoaixYtQvv27aU8Wq0WkydPxtq1a3Hv3j306dMHixcvRvPmza1SKSJqeFpO3QaVk0BqFyA8eQe0FYoa85+f06+OSkZEljC7B+Xu3buIjIzEwoULq9yempqKefPmYeHChcjJyYFarUZcXBxKSkqkPBMmTMDGjRuxbt06HDhwAHfu3EH//v1RUVFheU2IrCw5ORkKhcLgoVarpe1CCCQnJ0Oj0cDNzQ09e/bEyZMn7VhiIqL6w+welISEBCQkJFS5TQiB+fPnY/r06Rg8eDAAYNWqVQgMDMSaNWswatQo3L59GytWrMDXX3+N5557DgCQkZGB4OBg7Nq1C3379q1FdYisq3379ti1a5f03MnJSfq/PhhPT09HmzZtMHPmTMTFxeHs2bPw9PS0R3GJiOoNswOUmuTm5iI/Px/x8fFSmkqlQmxsLLKzszFq1CgcOXIEOp3OII9Go0F4eDiys7OrDFC0Wi20Wq30vLi4GACg0+mg0+msUnb9fqy1P2tQOQnT8zZ6kFdO5TeHLc6/Nfbl7Oxs0GuiZ0owTkRElrNqgJKfnw8ACAwMNEgPDAzEhQsXpDwuLi7w8fExyqN//aNmz56NlJQUo/SdO3fC3d3dGkWXZGZmWnV/tZHaxfzXyKn8lrBm+UtLS2u9j3PnzkGj0UClUiE6OhqzZs1Cq1atTArGq2KLYPvh4M6coNZScg2CVU5CCtT1/9ZErvWoiiOVlcharBqg6CkUhoPThBBGaY+qKc+0adMwceJE6XlxcTGCg4MRHx8PLy+v2hcYDy4AmZmZiIuLg1KptMo+ays8eYfJeVWNBD7uVCmr8pvDFudf/+VvqejoaKxevRpt2rTBtWvXMHPmTMTExODkyZMmBeNVsWWwnZmZaVFQa67t27fb/iAWeLjuH3eqfGx+udajKtYItokcjVUDFH1XeH5+PoKCgqT0goIC6UKuVqtRVlaGoqIig16UgoICxMTEVLlflUoFlUpllK5UKq3+ZWyLfVrqcbMQqiKn8lvCmuWv7X4eHmsVERGBbt26oXXr1li1ahW6du0KwPxg3BbB9sPBXcdP9li0D3OcSJbnOLHw5B1SoP7R4UbQVtb8+ZFrPapS22CbyBFZNUAJDQ2FWq1GZmYmOnbsCAAoKytDVlYWPv30UwBAVFQUlEolMjMzMWTIEABAXl4eTpw4gdTUVGsWh8iqPDw8EBERgXPnzklT62sKxqtiy2BbqVRaFNRachw5erju2krFY8+FXOtRFUcqK5G1mD3N+M6dOzh27BiOHTsG4MHA2GPHjuHixYtQKBSYMGECZs2ahY0bN+LEiRMYPnw43N3d8eqrrwIAvL29MXLkSEyaNAm7d+/G0aNH8dprryEiIkKa1UMkR1qtFqdPn0ZQUJBBMK6nD8ar6wkkIiLTmd2DcvjwYfTq1Ut6ru+uTkxMRHp6OqZMmYJ79+5h9OjR0g+17dy502Da5RdffAFnZ2cMGTJE+qG29PR0gymcRPY2efJkDBgwAC1atEBBQQFmzpyJ4uJiJCYmGgTjYWFhCAsLw6xZswyCcSIispzZAUrPnj0hRPUj5BUKBZKTk5GcnFxtHldXVyxYsAALFiww9/BEdeby5csYNmwYbty4gaZNm6Jr1644dOgQQkJCAMCkYJyIiCxjk1k8RPXBunXratxuSjBORESWYYBCRA1Sy6nbzH4N1+8hqjtczZiIiIhkhz0oRGQW9jwQUV1gDwoRERHJDgMUIiIikh3e4iEimzP3thBvCRERAxQikh1LxrkQUf3CWzxEREQkO/WyB0WO3cn8i5CIiMh07EEhIiIi2amXPSh1gT0iREREtsMeFCIiIpIdBihEREQkO7zFQ0RkIjkOwCeqr9iDQkRERLLDHhQ8+KtI5SSQ2gUIT94BbYXC3kUiIqJ6wtzvFfa8PcAeFCIiIpIdBihEREQkO7zFU8+wK5GIiOoD9qAQERGR7DBAISIiItlhgEJERESywwCFiIiIZIcBChEREcmOXQOUxYsXIzQ0FK6uroiKisKPP/5oz+IQWYxtmeoLtmWSC7tNM16/fj0mTJiAxYsX45lnnsGyZcuQkJCAU6dOoUWLFvYqFpHZ2JapOuau3QPYd+o/2zLJid16UObNm4eRI0firbfeQrt27TB//nwEBwdjyZIl9ioSkUXYlqm+YFsmObFLD0pZWRmOHDmCqVOnGqTHx8cjOzvbKL9Wq4VWq5We3759GwBw8+ZN6HQ6o/zO5XfNLpNzpUBpaSWcdY1QUel4a/FYWv7CwkKzjhM9e7e5RcO/p/V5bB6dTofS0lIUFhai+9z9VjlGSUkJAEAIYfb+TGXrtmzK+VY1EviwYyU6TN8AZwdsu9bk6J9joOrPpBzbMmB6e9Z/vs15X8y9NsmRJfUG5Ft3c75b9Z/FwsJCKJVKKd2stizs4MqVKwKA+L//+z+D9E8++US0adPGKH9SUpIAwAcfFj0uXbrEtsxHvXjIqS2zPfNRm4cpbdmuP3WvUBhGlEIIozQAmDZtGiZOnCg9r6ysxM2bN+Hn51dlfksUFxcjODgYly5dgpeXl1X2WZdYfmNCCJSUlECj0VhlfzWxZ1t29PfemurruZBjWwZMb8/19X15nIZab6D6upvTlu0SoPj7+8PJyQn5+fkG6QUFBQgMDDTKr1KpoFKpDNKaNGlik7J5eXk5dENi+Q15e3tbbV9VkVNbdvT33prq47mQW1sGzG/P9fF9MUVDrTdQdd1Nbct2GSTr4uKCqKgoZGZmGqRnZmYiJibGHkUisgjbMtUXbMskN3a7xTNx4kS8/vrr6NSpE7p164bly5fj4sWLePfdd+1VJCKLsC1TfcG2THJitwBl6NChKCwsxIwZM5CXl4fw8HBs374dISEhdimPSqVCUlKSUXelo2D57cfebdmRz5218VzUjq3ackN9XxpqvQHr1F0hhA3nrRERERFZgGvxEBERkewwQCEiIiLZYYBCREREssMAhYiIiGSnwQco58+fx8iRIxEaGgo3Nze0bt0aSUlJKCsrM8inUCiMHkuXLrVLma9evYrk5GQcO3ZMStMvke7k5AQnJyeTlkhXKBRITk4269j79u2DQqHAP/7xDzNLDcyePRudO3eGp6cnAgICMGjQIJw9e9Ygz/Dhw43Oc9euXc0+VkOif++VSqXBeXN2dkZQUBBeeeUVnDt3zuA1PXv2hEKhwPPPP2+0v/Pnz0OhUGDu3LlSmv59r+rx8ssvG+w3PDzcrPJ/+OGHUCgUZr1u//79GDBgADQaDRQKBTZt2mSwXQiB5ORkaDQauLm5oWfPnjh58qRZ5SLr0LdPV1dXREVFmXRtqg8e10brK1Ou86Zq8AHKmTNnUFlZiWXLluHkyZP44osvsHTpUnzwwQdGedPS0pCXlyc9EhMT7VDiBwFKSkqKFKDol0ifPn06Bg4cCCcnJyQkJODixYs17ufgwYN466236qDED2RlZWHMmDE4dOgQMjMzUV5ejvj4eNy9a7gA1fPPP29wnrdv315nZXQ0D7/3KSkpAB784NbGjRuxa9cujB07Flu2bEH37t1RVFRk9PodO3Zgz549Jh9v1qxZOHjwoMFj9uzZFpf/2LFjmDt3brW/VFqdu3fvIjIyEgsXLqxye2pqKubNm4eFCxciJycHarUacXFx0kJlVDcebp9Hjx7Fs88+a9K1qT54XButr0y9zpukNotL1UdlZWVi9uzZIjQ01CAdgNi4caN9CvWInJwcAUCkpaUJIYTo0qWLePfdd4UQQiQmJgoPDw/Rtm1bMXXqVKsfe+/evQKA+O6772q9r4KCAgFAZGVlSWmJiYnixRdfrPW+G4qH3/u0tDQBQISEhBi89ykpKQKAWLlypZQWGxsr2rRpI1q1aiWioqJEZWWltC03N1cAEJ999pmUZur7HhsbK9q3b29S2XU6nejQoYN47733zHrdox79bFZWVgq1Wi3mzJkjpd2/f194e3uLpUuXWnQMsszD7VPPVtcmOZPT90ddq+o6byqH7UE5c+YMhg0bhsDAQKhUKrRo0QJvvPGGtPT3iRMn8OKLL8LHxweurq7o0KEDVq1aZbAPfbf1119/jUmTJqFZs2ZQqVQ4f/48iouL0bhxY/z222944YUXAAAvv/wy3NzcEBUVhaVLl6KyshLAg2XKZ86cibZt20KlUqFp06YYMWIErl+/bnC89evXIz4+HkFBQXBzc0O7du0wdepUsyLLffv2oXPnzgCAESNGQKFQ4KeffsLNmzcN8nXp0gXLli1D48aNERwcjEmTJhksiw5UfYvnypUreOeddxAcHAwXFxdoNBq8/PLLuHbtWrVlKi4uRt++fREYGIiffvoJAJCcnAyFQoGTJ09i2LBh8Pb2RmBgIN58801pSXb9vz4+Pli8eDE6dOiAjIwMbN68GSqVCqGhoXj77bdRUFAAADh69Cj69++PgIAAqFQqaDQa9OvXD5cvX5bK8t133yE6Ohre3t5wd3dHq1at8Oabb5p8fh1JWVkZjhw5gvj4eIP0rl27Ijs7W3reqVMnADB6D5VKJT755BMcOXIE69evt32BHzFnzhzcvHkTn3zyiVmv099GOnjwoPQT7O+88w7S0tIAACtXrkR+fj6Sk5MRERGBH374ASqVCrGxsdJ5OXfuHF599VWpLbVr1w6LFi0yOM79+/cxadIkdOjQAd7e3vD19UW3bt2wefNmozIpFAqMHTsWX3/9Ndq1awd3d3dERkbiX//6lyWnpl6orn3Gx8cbtE+q3/TXeV9fX7Nfa9fVjC31888/o3v37vD398eMGTMQFhaGvLw8bNmyBWVlZTh//jxiYmIQEBCAL7/8En5+fsjIyMDw4cNx7do1TJkyxWB/06ZNQ7du3bB06VJcu3YNEydORHh4OI4cOYKBAwdi5MiRCAwMRKNGjZCWlgZ/f39MmjQJN27cwAcffIAXX3wRP/74I6ZMmYKYmBhcuHABSUlJ6NmzJw4fPgw3NzcADy6KL7zwAiZMmAAPDw+cOXMGn376KX766SeTu9mffvpppKWlYcSIEfjwww/RpUsXDBw4EMOGDZPy6HQ6fP/993BycsLmzZuxf/9+fPzxx/D29sbf/va3avd95coVdO7cGTqdDh988AGeeuopFBYWYseOHSgqKqqyG/7y5ct44YUXUFZWhoMHD6JVq1YG21966SUMHToUI0eOxPHjxzFt2jQAwIoVKzBx4kR0794dCxYsQHp6Ot577z288MILKC8vxz/+8Q8UFRUhOzsbvXv3xv79+xEXF4fQ0FAsWrQIgYGByM/Px969e6Vu+4MHD2Lo0KEYOnQokpOT4erqigsXLph1C8OR3LhxAxUVFUbvi6+vL44ePSo9z83NBQC0adPGaB9Dhw7F3Llz8eGHH+Kll16CUqms8ZiVlZUoLy83SHN2Nv8ycurUKcycORMbNmxA48aNzX59fn4+RowYgSlTpuDgwYMICQnBm2++iUuXLmH16tUAgK+++gqLFi3CoEGD8PvvvyMwMBAXLlzAqVOnEBMTgxYtWuDzzz+HWq3Gjh078N577+HGjRtISkoCAGi1Wty8eROTJ09Gs2bNUFZWhl27dmHw4MFIS0vDG2+8YVCmbdu2IScnBzNmzEDjxo2RmpqKP/7xjzh79qzR56IhqK596j+7VP8JIaTrvLlj0/Q7cDi9e/cWTZo0EQUFBVVuf+WVV4STk5MAUONj6dKlAoDo0aOHEEKIK1euiD/84Q9i5MiRIjExUQAQ3377rcG+X3jhBfHEE0+IuXPnCi8vL7F27VoBQPzzn/80yKe/DbN48eIqy1hZWSl0Op3IysoSAMTPP/9scv0fvsVz5coVAUBkZ2cLIYRU7ldeeUU88cQTRuV+GACRlJQkPX/zzTeFUqkUp06dqvbYD3f1Hz16VGg0GvHss8+KwsJCg3xJSUkCgEhNTTVIHz16tHB1dRV//vOfRUhIiNi8ebMAID7//HODfJcuXRJubm5i9OjRQqlUitTUVAFAbNq0qdqyzZ07VwAQt27dqjZPffLoe6+/xTNq1CjRpk0bUVJSIn744QehVqtFjx49hE6nk1778C2VXbt2CQBiwYIFQoiab/FU9Th37lyV+61ORUWFiI6OFsOGDTPrdQ/nBSAOHz4shHjQjlevXi2cnJyEm5ub2LRpkwAgrl69Ko4dOyYAiC+//FK89dZbom/fvqJv376iefPm4vbt2wb7HTt2rHB1dRU3b96s8rjl5eVCp9OJkSNHio4dOxpsAyACAwNFcXGxlJafny8aNWokZs+ebVK96ptH26fezJkzja5F9R0a6C2e0aNHi5CQEHHp0iWLXu9wt3hKS0uRlZWFIUOGoGnTplXm2bNnD3r16oXTp08bPObNmwcAWL58OU6fPo3Q0FAAD/7Kv3r1Knr16iUtkAU86LYdMGCAwb6feuopXLhwAV27dkVxcTH+8Y9/oEmTJhgwYADKy8ulR4cOHaBWq7Fv3z7ptb///jteffVVqNVqODk5QalUIjY2FgBw+vRpi85HVUukKxQK+Pr6Gvzloi93Tb7//nv06tUL7dq1e+xxd+zYgWeffRY9evRAZmZmtd13AwcONHj+1FNP4f79+9i0aRP27t2Ln376CQqFAq+99prB+VOr1YiMjMThw4cREhKC0tJS+Pj44P3338fSpUtx6tQpo2Ppb30NGTIE3377La5cufLYejiyqt57AFi2bBl+/fVXeHp64vnnn4ePjw82b95cbU9Hnz59EB8fjxkzZjx2EOmnn36KnJwcg0dwcLBZ5Z43bx7OnTuH+fPnm/W6hwUFBSEqKkp6rp8x0KFDB0RERAB40Muib8sXLlxAQUEB/P39sXv3bvzxj3+Eu7u7QZt74YUXcP/+fRw6dEja73fffYdnnnkGjRs3hrOzM5RKJVasWFHl57VXr17w9PSUngcGBiIgIOCxn7v6qrr2WVBQYPagaHI848aNw5YtW7B37140b97con04XIBSVFSEioqKGitcWFiIkJAQtG3b1uCh/wJzd3dH27Zt4eLiAuDBokY9e/aUbp80atRIyufq6mqwb5VKhfv37+Po0aNwdXVFUVERbt26BRcXFyiVSoNHfn4+bty4AQC4c+cOnn32Wfz73//GzJkzsW/fPuTk5GDDhg0AgHv37ll0PqpaIt3d3R179+41WCJdX+6aXL9+3eSGtGnTJty7dw9//vOfa1wMys/PT/q/EALffvstAOCbb75BaGgorl27BiEEAgMDjc7foUOHUFBQgEuXLiE0NBRZWVno0KEDPvjgA7Rv3x4ajQZJSUnQ6XQAgB49emDTpk0oLy/HG2+8gebNmyM8PBxr1641qU6Opqr3HgA0Gg0SExOxZ88ejBo1CqdPnza4BViVTz/9FDdu3DCYWlyVVq1aoVOnTgYPcxYDu3jxIv72t78hKSkJLi4uuHXrFm7duoXy8nJUVlbi1q1bJn0WqgqIXVxc4Ovri9DQUKjVamRmZkqf8bt37yIrKwvh4eEoLy/HggULjNqbfqyZ/jO7YcMGDBkyBM2aNUNGRgYOHjyInJwcvPnmm1V+lh5u63oqlcriz7ajq659ZmZmGlybqH4RQmDs2LHYsGED9uzZI3UEWMLhxqD4+vrCycnJYGDko/z8/JCXl2eUfvXqVQAPIvuHJScn48knn8TcuXOlga0PX1S2bt2K/Px8dOvWTRqMOn36dLzzzjsoKCiAn58ffvjhhyrLov+Las+ePbh69Sr27dsn9ZoAwK1bt0yodc0eXiL99u3bKCsrs2iJ9KZNm9Z4Xh/2xRdfYP369UhISMDGjRuNBsJVZcyYMTh48CAAoHHjxsjPz4erqysUCgV+/PFHVFRUYPny5ejduzf8/f2Rl5eHxYsXQ6fT4Y9//CM8PT2xbt06CCHwyy+/ID09HTNmzICbmxumTp0KAHjxxRfx4osvQqvV4tChQ5g9ezZeffVVtGzZEt26dTPrfDiCh997/V+qN2/eREpKCkJCQtCrVy9UVFTgf//3f/GPf/zD4DdLHtahQwcMGzYM8+bNk76obeH333/HvXv3MH78eIwfP95ou4+PD8aPH//Y3pXKykqD3wHKzc1FWVkZ7t27B4VCgQkTJmDWrFkICwsDAOzevRvu7u7S2K3XX38dY8aMqXLf+gtqRkYGQkNDsX79eigUCmn7o4PNqXoPt09977Ql1yZHdOfOHfz222/S89zcXBw7dgy+vr5o0aKFHUtmW2PGjMGaNWuwefNmeHp6Stclb29vaTymyax4u6nO9O7dW/j4+Ijr169XuX3YsGHC1dVVXLlyxSC9X79+wt3dXRqjUNN9dQDCw8NDCCHE999/Lzp06CAaN24snJ2dBQAxf/58odPpREZGhgAgDh06VGOZt2zZIgCIgwcPGqS//PLLBlOGTfHLL78YjW9ZtGiRCAkJEY0aNRKNGjUymtKlHxPyMFQzBuXMmTPVHvvhMShlZWViyJAhQqVSGY0N0R/v4feopnO9fv16UVpaKuLj40XTpk2FUqkULVq0EImJieLixYvVlqdJkybiT3/6U7Xb9WMQFi1aVG0eR6d/7/XjrpYtW2aw/ebNm8LHx0e0a9dOVFRUCCGqHvPx+++/CxcXF5GQkGCzacZFRUVi7969Ro/IyEjRsmVLsXfvXoMxLdUdo2XLllW2o+bNmwshHozxSkpKEmq1WgAQGo1GHD9+XAghxHPPPSciIyOFVqut8TiDBw82GiuRl5cnGjduXOVnacyYMUb7CAkJEYmJiTUep77Tt08XFxfx9NNPWzTd1BFV9/1S39tDddd4c77jpH1Zv3i2d+zYMdG4cWPRqlUrsXz5crFnzx6xdu1aMWzYMFFcXCzOnDkjPD09RZs2bURGRobYvn27+J//+R+jQZs1XXT1vyfyqEe/6MvLy0VCQoLw9fUVKSkp4vvvvxe7du0S6enpIjExUWzYsEEIIcSNGzeEj4+PiIyMFBs2bBBbt24Vr7zyiggLCzP7zbt7965wc3MTzzzzjNi7d6/IycmRgjFTyy2EcYBy+fJlERQUJAICAsT8+fPF7t27xT//+U/x9ttvi9OnT1d5zioqKsSIESOEs7OzWLNmjdHxHg0i9QM5c3NzpbR33nlHuLu7i7/+9a9i69atYs+ePeKbb74Rf/7zn6UgbOvWrSIhIUEsW7ZMZGZmip07d4p3331XABDLly8XQgjx0UcfiREjRoiMjAyxb98+sWnTJtGrVy+hVCrFiRMnTD6/jkp/bnNycoy26QcZf/3110KI6gOJ8ePHSxcUSwOU4OBg8d133xk99u3bV+PrqipP7969hZOTk0l5Q0JCRL9+/YzSHw0eTp48KXx8fESXLl1EWlqa2Lt3r9iyZYuYN2+e6NWrl5Rv5cqVAoD485//LHbv3i3S09NF69atpc9sTcd4uEz1/QuJyFYc7hYPAERGRuKnn35CUlISpk2bhpKSEqjVavTu3RsuLi544oknkJ2djQ8++ABjxozBvXv30K5dO6SlpWH48OFWLYuTkxO2bNmCv//97/j6668xe/ZsODs7o3nz5oiNjZUG7Pn5+WHbtm2YNGkSXnvtNXh4eODFF1/E+vXr8fTTT5t1THd3d6xcuRIpKSmIj4+HTqdDUlKS2T9b/6hmzZpJ53XOnDkoLCxE06ZN0b1792oHwTZq1AgrVqyAp6cnXnvtNdy9e9fsX6ddtmwZunbtimXLlmHx4sWorKyERqPBM888gy5dugAAwsLC0KRJE6SmpuLq1avS+5yeni79om90dDQOHz6M999/H9evX0eTJk3QqVMn7NmzB+3bt6/VuXF048aNw8KFCzFjxowax6N8+OGHSEtLQ3FxscXHunTpEv70pz8ZpcfGxhoMGjdFRUUFKioqLC5LVZ588kn85z//wccff4wPP/wQBQUFaNKkCcLCwgxub40YMQIFBQVYunQpVq5ciVatWmHq1Km4fPmy9Ku9RGQ7CiGEsHchiIiIiB7mcLN4iIiIqP5zyFs89ZUQ4rHd2U5OTgYzCoiIiOoj9qDISFZWltFvMzz6eHQ9ISIiovqIY1BkpKSkBGfPnq0xT2hoaJU/CEVERFSfMEAhIiIi2eEtHiIiIpIdhxwkW1lZiatXr8LT05MDRqlaQgiUlJRAo9FI6yvJDdsymcIR2jKRtTlkgHL16lWzV1ClhuvSpUsWr6Zpa2zLZA45t2Uia3PIAEW/AN+lS5fg5eVl59KYRqfTYefOnYiPj4dSqbR3cWTB1uekuLgYwcHBUnuRI7m1ZUdqpw2prI7QlomszSEDFH1XuJeXlywu6qbQ6XRwd3eHl5eX7C+mdaWuzomcb53IrS07UjttiGWVc1smsjbezCQiIiLZMTtA2b9/PwYMGACNRgOFQoFNmzYZbBdCIDk5GRqNBm5ubujZsydOnjxpkEer1WLcuHHw9/eHh4cHBg4ciMuXL9eqIkRERFR/mH2L5+7du4iMjMSIESPw0ksvGW1PTU3FvHnzkJ6ejjZt2mDmzJmIi4vD2bNnpfunEyZMwNatW7Fu3Tr4+flh0qRJ6N+/P44cOQInJ6fa16qeaDl1m82PcX5OP5sfg8hcprR9lZNAahcgPHkHtBUKtmWiesbsACUhIQEJCQlVbhNCYP78+Zg+fToGDx4MAFi1ahUCAwOxZs0ajBo1Crdv38aKFSvw9ddf47nnngMAZGRkIDg4GLt27ULfvn1rUR0iIiKqD6w6SDY3Nxf5+fmIj4+X0lQqFWJjY5GdnY1Ro0bhyJEj0Ol0Bnk0Gg3Cw8ORnZ1dZYCi1Wqh1Wql58XFxQAeDDzT6XTWrILN6MtpTnlVTrb/kV97nj9Lzokl+yciIsdj1QAlPz8fABAYGGiQHhgYiAsXLkh5XFxc4OPjY5RH//pHzZ49GykpKUbpO3fuhLu7uzWKXmcyMzNNzpvaxYYF+f9t377d9gd5DHPOiTlKS0ttsl8iIrI9m0wzfnQqnBDisdPjasozbdo0TJw4UXqu/02A+Ph4WUzNNIVOp0NmZibi4uJMnmYYnrzDxqUCTiTb75aaJefEHPqeNiIicjxWDVDUajWAB70kQUFBUnpBQYHUq6JWq1FWVoaioiKDXpSCggLExMRUuV+VSgWVSmWUrlQqZf/7B48yp8zaCtv/5oEczp+t3kc51I2IiCxj1d9BCQ0NhVqtNuiyLysrQ1ZWlhR8REVFQalUGuTJy8vDiRMnqg1QiIiIqGExuwflzp07+O2336Tnubm5OHbsGHx9fdGiRQtMmDABs2bNQlhYGMLCwjBr1iy4u7vj1VdfBQB4e3tj5MiRmDRpEvz8/ODr64vJkycjIiJCmtVDREREDZvZAcrhw4fRq1cv6bl+bEhiYiLS09MxZcoU3Lt3D6NHj0ZRURGio6Oxc+dOgzUkvvjiCzg7O2PIkCG4d+8e+vTpg/T0dP4GChEREQGwIEDp2bMnhKh++qtCoUBycjKSk5OrzePq6ooFCxZgwYIF5h6eiIiIGgCuxUNERESywwCFGiyuK0VEJF8MUKjB0q8rtXDhwiq369eVWrhwIXJycqBWqxEXF4eSkhIpz4QJE7Bx40asW7cOBw4cwJ07d9C/f39UVFTUVTWIiOolm/xQG5Ej4LpSRETyxQCFqAoNdV0pW6+PZCpT1qFSNRIG/9q7zDWp7XmVc92IbIUBClEVGvq6UrZaH8lU5qxD9XGnSgDyWFfqcSw9r1xXihoiBigNXMup28zKf35OPxuVRJ4a2rpStl4fyVSmrEOlaiTwcadKfHS4EbSVCruuK/U4tT2vXFeKGiIGKERVaOjrStm7POasQ6WtVEBboZDV+auOpefVEepGZG2cxUNUBa4rRURkX+xBoQaL60oREckXAxRqsLiuFBGRfDFAoQaL60oREckXx6AQERGR7DBAISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHU4zJiKbM3fNJyIi9qAQERGR7DBAISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHU4zJqJ6wdypzOfn9LNRSYjIGtiDQkRERLLDAIWIiIhkhwEKERERyQ4DFCIiIpIdDpIlauAeHlyqchJI7QKEJ++AtkJRZX4OLiWiusAeFCIiIpIdBihEREQkO7zFQ2Yx97cmAN4SICIi87EHhYiIiGSHAQoRERHJjtVv8SQnJyMlJcUgLTAwEPn5+QAAIQRSUlKwfPlyFBUVITo6GosWLUL79u2tXRQisgFLbvMREZnLJj0o7du3R15envQ4fvy4tC01NRXz5s3DwoULkZOTA7Vajbi4OJSUlNiiKEREROSAbDJI1tnZGWq12ihdCIH58+dj+vTpGDx4MABg1apVCAwMxJo1azBq1ChbFEcWwpN3PPb3JYiIiOgBmwQo586dg0ajgUqlQnR0NGbNmoVWrVohNzcX+fn5iI+Pl/KqVCrExsYiOzu72gBFq9VCq9VKz4uLiwEAOp0OOp3OFlWwOlUjYfBvQ1Lde6RPt9V76Chtg4iIjFk9QImOjsbq1avRpk0bXLt2DTNnzkRMTAxOnjwpjUMJDAw0eE1gYCAuXLhQ7T5nz55tNK4FAHbu3Al3d3frVsBGPu6k/7fSvgWxg+3bt9e4PTMz0ybHLS0ttcl+iYjI9qweoCQkJEj/j4iIQLdu3dC6dWusWrUKXbt2BQAoFIa3OIQQRmkPmzZtGiZOnCg9Ly4uRnBwMOLj4+Hl5WXlGthG1Iwf8HGnSnx0uBG0lQ3rFs+J5L5Vput0OmRmZiIuLg5KpdLqx9X3tBERkeOx+Q+1eXh4ICIiAufOncOgQYMAAPn5+QgKCpLyFBQUGPWqPEylUkGlUhmlK5VKm3yx2YI+KNFWKhrcGJTHvUe2eh9ru0/OSCMish+b/w6KVqvF6dOnERQUhNDQUKjVaoMu/bKyMmRlZSEmJsbWRSEyG2ekERHZh9V7UCZPnowBAwagRYsWKCgowMyZM1FcXIzExEQoFApMmDABs2bNQlhYGMLCwjBr1iy4u7vj1VdftXZRiGqNM9KIiOzD6gHK5cuXMWzYMNy4cQNNmzZF165dcejQIYSEhAAApkyZgnv37mH06NFSt/jOnTvh6elp7aIQ1VpDmJGmcvp/M8scabZZbctal+e7tjPWOCONGiKrByjr1q2rcbtCoUBycjKSk5OtfWgiq2ooM9JSuxinOdJsM0vL+rjZZbZg6Yw1zkijhoirGRNVo6HMSAtP3iH9X9VIOMxss9qWtbrZZbZQ2xlrnJFGDREDFCIT1dcZaVXNKnOk2WaWltUe59vS99lRZisSWRNXMyYyEWekERHVHfagEFWDM9KIiOyHAQpRNRxxRlrLqdvsdmwiImtigEJUDc5IIyKyH45BISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHc7isZC50zlVTjYqiAOo7lypnARSuzz4qfWHfwn0/Jx+dVU0asAsmZLNtklUd9iDQkRERLLDAIWIiIhkhwEKERERyQ4DFCIiIpIdBihEREQkOwxQiIiISHYYoBAREZHsMEAhIiIi2WGAQkRERLLDX5KFZb8oSURERLbDHhQiIiKSHQYoREREJDsMUIiIiEh2GKAQERGR7DBAISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2GKAQERGR7HCxQJIdSxZvPD+nnw1KQkRE9lIvAxSuTkz1BdsyETVUdr3Fs3jxYoSGhsLV1RVRUVH48ccf7VkcIouxLRMRWZfdApT169djwoQJmD59Oo4ePYpnn30WCQkJuHjxor2KRGQRtmUiIuuzW4Ayb948jBw5Em+99RbatWuH+fPnIzg4GEuWLLFXkYgswrZMRGR9dhmDUlZWhiNHjmDq1KkG6fHx8cjOzjbKr9VqodVqpee3b98GANy8eRM6nc4ov3P5XSuXuPacKwVKSyvhrGuEikqFvYsjC9Y8J4WFhUZpJSUlAAAhRK32XZP61pYdqZ3ao6xVtbOaRM/eDQBQNRL4sGMlOkzfAO1jyvrvaX2M0uqiLRPJjV0ClBs3bqCiogKBgYEG6YGBgcjPzzfKP3v2bKSkpBilh4aG2qyMtvCqvQsgQ9Y6J/6fV7+tpKQE3t7eVjqSofrYlh2pndZ1WWtqZ49jalnt1ZaJ5Maus3gUCsO/JIQQRmkAMG3aNEycOFF6XllZiZs3b8LPz6/K/HJUXFyM4OBgXLp0CV5eXvYujizY+pwIIVBSUgKNRmP1fT+qvrRlR2qnDamsddmWieTCLgGKv78/nJycjP7CLCgoMPpLFABUKhVUKpVBWpMmTWxZRJvx8vKS/cW0rtnynNj6r8362pYdqZ02lLKy54QaGrsMknVxcUFUVBQyMzMN0jMzMxETE2OPIhFZhG2ZiMg27HaLZ+LEiXj99dfRqVMndOvWDcuXL8fFixfx7rvv2qtIRBZhWyYisj67BShDhw5FYWEhZsyYgby8PISHh2P79u0ICQmxV5FsSqVSISkpyah7vyGrL+ekPrVlR3pPWFai+k0hOG+NiIiIZIarGRMREZHsMEAhIiIi2WGAQkRERLLDAIWIiIhkhwEKERERyQ4DlFpITk6GQqEweKjVamm7EALJycnQaDRwc3NDz549cfLkSYN9aLVajBs3Dv7+/vDw8MDAgQNx+fLluq6KVV25cgWvvfYa/Pz84O7ujg4dOuDIkSPS9oZ6XuTCGu3WVvbv348BAwZAo9FAoVBg06ZNBtvl1HYeV9bhw4cbneeuXbvapaxEjogBSi21b98eeXl50uP48ePSttTUVMybNw8LFy5ETk4O1Go14uLipJVJAWDChAnYuHEj1q1bhwMHDuDOnTvo378/Kioq7FGdWisqKsIzzzwDpVKJ77//HqdOncLnn39u8HPuDfG8yE1t262t3L17F5GRkVi4cGGV2+XUdh5XVgB4/vnnDc7z9u3bDbaznRPVQJDFkpKSRGRkZJXbKisrhVqtFnPmzJHS7t+/L7y9vcXSpUuFEELcunVLKJVKsW7dOinPlStXRKNGjcQPP/xg07Lbyvvvvy+6d+9e7faGel7kpLbttq4AEBs3bjSrbPZqO4+WVQghEhMTxYsvvljta9jOiWrGHpRaOnfuHDQaDUJDQ/HKK6/g999/BwDk5uYiPz8f8fHxUl6VSoXY2FhkZ2cDAI4cOQKdTmeQR6PRIDw8XMrjaLZs2YJOnTrhT3/6EwICAtCxY0d89dVX0vaGel7kpjbt1l4cse3s27cPAQEBaNOmDd5++20UFBRI2+RWViK5YYBSC9HR0Vi9ejV27NiBr776Cvn5+YiJiUFhYaG0uu2jK9oGBgZK2/Lz8+Hi4gIfH59q8zia33//HUuWLEFYWBh27NiBd999F++99x5Wr14NAA32vMhJbdutvTha20lISMA333yDPXv24PPPP0dOTg569+4NrVYru7ISyZHd1uKpDxISEqT/R0REoFu3bmjdujVWrVolDYZTKBQGrxFCGKU9ypQ8clVZWYlOnTph1qxZAICOHTvi5MmTWLJkCd544w0pX0M7L3Jiq3ZbVxyl7QwdOlT6f3h4ODp16oSQkBBs27YNgwcPrvZ1cjrXRPbEHhQr8vDwQEREBM6dOyfNinj0L6GCggLpL0C1Wo2ysjIUFRVVm8fRBAUF4cknnzRIa9euHS5evAgADfa8yJm57dZeHL3tBAUFISQkBOfOnQMg77ISyQEDFCvSarU4ffo0goKCEBoaCrVajczMTGl7WVkZsrKyEBMTAwCIioqCUqk0yJOXl4cTJ05IeRzNM888g7Nnzxqk/frrr9LKvg31vMiZue3WXhy97RQWFuLSpUsICgoCIO+yEsmC/cbnOr5JkyaJffv2id9//10cOnRI9O/fX3h6eorz588LIYSYM2eO8Pb2Fhs2bBDHjx8Xw4YNE0FBQaK4uFjax7vvviuaN28udu3aJf7zn/+I3r17i8jISFFeXm6vatXKTz/9JJydncUnn3wizp07J7755hvh7u4uMjIypDwN8bzIiTXara2UlJSIo0ePiqNHjwoAYt68eeLo0aPiwoULJpetrtpOTWUtKSkRkyZNEtnZ2SI3N1fs3btXdOvWTTRr1oztnMhEDFBqYejQoSIoKEgolUqh0WjE4MGDxcmTJ6XtlZWVIikpSajVaqFSqUSPHj3E8ePHDfZx7949MXbsWOHr6yvc3NxE//79xcWLF+u6Kla1detWER4eLlQqlWjbtq1Yvny5wfaGel7kwhrt1lb27t0rABg9EhMTTS5bXbWdmspaWloq4uPjRdOmTYVSqRQtWrQQiYmJRuVgOyeqnkIIIezTd0NERERUNY5BISIiItlhgEJERESywwCFiIiIZIcBChEREckOAxQiIiKSHQYoREREJDsMUIiIiEh2GKAQERGR7DBAISIiItlhgEJERESywwCFiIiIZOf/A84KfAUzvXgYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>age</th>\n",
       "      <th>ocular_pressure</th>\n",
       "      <th>MD</th>\n",
       "      <th>PSD</th>\n",
       "      <th>GHT</th>\n",
       "      <th>cornea_thickness</th>\n",
       "      <th>RNFL4.mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.595190</td>\n",
       "      <td>56.845691</td>\n",
       "      <td>20.963928</td>\n",
       "      <td>-8.661383</td>\n",
       "      <td>5.512084</td>\n",
       "      <td>1.248497</td>\n",
       "      <td>540.308617</td>\n",
       "      <td>82.551770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491348</td>\n",
       "      <td>15.408306</td>\n",
       "      <td>8.546982</td>\n",
       "      <td>10.296883</td>\n",
       "      <td>4.262622</td>\n",
       "      <td>0.930503</td>\n",
       "      <td>33.594752</td>\n",
       "      <td>25.779878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-32.510000</td>\n",
       "      <td>-1.590000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-14.725000</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>62.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-4.020000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>542.000000</td>\n",
       "      <td>86.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-1.740000</td>\n",
       "      <td>9.355000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>563.500000</td>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>32.690000</td>\n",
       "      <td>17.120000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         glaucoma         age  ocular_pressure          MD         PSD  \\\n",
       "count  499.000000  499.000000       499.000000  499.000000  499.000000   \n",
       "mean     0.595190   56.845691        20.963928   -8.661383    5.512084   \n",
       "std      0.491348   15.408306         8.546982   10.296883    4.262622   \n",
       "min      0.000000    8.000000         8.000000  -32.510000   -1.590000   \n",
       "25%      0.000000   47.000000        15.000000  -14.725000    2.075000   \n",
       "50%      1.000000   57.000000        18.000000   -4.020000    3.240000   \n",
       "75%      1.000000   67.000000        25.000000   -1.740000    9.355000   \n",
       "max      1.000000   87.000000        65.000000   32.690000   17.120000   \n",
       "\n",
       "              GHT  cornea_thickness  RNFL4.mean  \n",
       "count  499.000000        499.000000  499.000000  \n",
       "mean     1.248497        540.308617   82.551770  \n",
       "std      0.930503         33.594752   25.779878  \n",
       "min      0.000000        445.000000   16.000000  \n",
       "25%      0.000000        519.000000   62.333333  \n",
       "50%      2.000000        542.000000   86.666667  \n",
       "75%      2.000000        563.500000  102.000000  \n",
       "max      2.000000        625.000000  162.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RL</th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>age</th>\n",
       "      <th>ocular_pressure</th>\n",
       "      <th>MD</th>\n",
       "      <th>PSD</th>\n",
       "      <th>GHT</th>\n",
       "      <th>cornea_thickness</th>\n",
       "      <th>RNFL4.mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OD</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0</td>\n",
       "      <td>558</td>\n",
       "      <td>103.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OS</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>107.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OD</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2</td>\n",
       "      <td>490</td>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OS</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2</td>\n",
       "      <td>495</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OD</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2</td>\n",
       "      <td>547</td>\n",
       "      <td>74.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RL  glaucoma  age  ocular_pressure    MD   PSD  GHT  cornea_thickness  \\\n",
       "0  OD         0   62               17 -0.54  1.81    0               558   \n",
       "1  OS         0   62               17 -0.64  1.38    0               564   \n",
       "2  OD         0   66               12 -1.65  2.89    2               490   \n",
       "3  OS         0   66               12 -1.14  3.88    2               495   \n",
       "4  OD         1   53               24 -2.90  3.78    2               547   \n",
       "\n",
       "   RNFL4.mean  \n",
       "0  103.333333  \n",
       "1  107.666667  \n",
       "2  162.000000  \n",
       "3   99.000000  \n",
       "4   74.666667  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>age</th>\n",
       "      <th>ocular_pressure</th>\n",
       "      <th>MD</th>\n",
       "      <th>PSD</th>\n",
       "      <th>GHT</th>\n",
       "      <th>cornea_thickness</th>\n",
       "      <th>RNFL4.mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0</td>\n",
       "      <td>558</td>\n",
       "      <td>103.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>107.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2</td>\n",
       "      <td>490</td>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2</td>\n",
       "      <td>495</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2</td>\n",
       "      <td>547</td>\n",
       "      <td>74.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "      <td>109.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>109.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0</td>\n",
       "      <td>566</td>\n",
       "      <td>110.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0</td>\n",
       "      <td>545</td>\n",
       "      <td>120.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>111.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     glaucoma  age  ocular_pressure    MD   PSD  GHT  cornea_thickness  \\\n",
       "0           0   62               17 -0.54  1.81    0               558   \n",
       "1           0   62               17 -0.64  1.38    0               564   \n",
       "2           0   66               12 -1.65  2.89    2               490   \n",
       "3           0   66               12 -1.14  3.88    2               495   \n",
       "4           1   53               24 -2.90  3.78    2               547   \n",
       "..        ...  ...              ...   ...   ...  ...               ...   \n",
       "494         0   13               15 -2.44  2.49    0               531   \n",
       "495         0   55               15 -1.21  2.17    0               562   \n",
       "496         0   55               16 -0.84  1.86    0               566   \n",
       "497         0   55               18 -0.43  1.91    0               545   \n",
       "498         0   55               18 -0.62  2.46    0               542   \n",
       "\n",
       "     RNFL4.mean  \n",
       "0    103.333333  \n",
       "1    107.666667  \n",
       "2    162.000000  \n",
       "3     99.000000  \n",
       "4     74.666667  \n",
       "..          ...  \n",
       "494  109.666667  \n",
       "495  109.333333  \n",
       "496  110.333333  \n",
       "497  120.666667  \n",
       "498  111.666667  \n",
       "\n",
       "[499 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_df(df):\n",
    "    df = df.drop(['RL'], axis=1)\n",
    "    return df\n",
    "# df = numpy.where(df['col_770'] == '22728486', 0, 1)\n",
    "df = clean_df(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataset):\n",
    "    return tf.keras.utils.normalize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(data):\n",
    "    y = numpy.array(data[data.columns[0]].values)\n",
    "    X = numpy.array(data.drop(data.columns[0], axis=1).values)\n",
    "    data = numpy.array(numpy.hstack((X, numpy.reshape(y, (-1, 1)))))\n",
    "    \n",
    "    return data.astype(float), X.astype(float), y.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\progdata\\anaconda\\envs\\ml\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = numpy.split(df.sample(frac=1), [int(0.6 * len(df)), int(0.8 * len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, X_train, y_train = scale_dataset(train)\n",
    "valid_data, X_valid, y_valid = scale_dataset(valid)\n",
    "test_data, X_test, y_test = scale_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10922218,  0.06182388, -0.02161775, ...,  0.00412159,\n",
       "         0.98299966,  0.13051708],\n",
       "       [ 0.13156549,  0.02133494, -0.01497002, ...,  0.00177791,\n",
       "         0.97251786,  0.19023658],\n",
       "       [ 0.08324163,  0.04162081, -0.03702361, ...,  0.00378371,\n",
       "         0.99133213,  0.08071916],\n",
       "       ...,\n",
       "       [ 0.14428738,  0.09619158, -0.02733765, ...,  0.00384766,\n",
       "         0.97923033,  0.09939797],\n",
       "       [ 0.11546572,  0.05959521, -0.03274012, ...,  0.0037247 ,\n",
       "         0.98518332,  0.10429162],\n",
       "       [ 0.03067208,  0.03428056, -0.00806495, ...,  0.00180424,\n",
       "         0.98511495,  0.16538865]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "X_valid = normalize(X_valid)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (7, 4))\n",
    "  ax1.plot(history.history['loss'], label='loss')\n",
    "  ax1.plot(history.history['val_loss'], label='val_loss')\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.set_ylabel('Binary crossentropy')\n",
    "  ax1.grid(True)\n",
    "\n",
    "  ax2.plot(history.history['accuracy'], label='accuracy')\n",
    "  ax2.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "  ax2.set_xlabel('Epoch')\n",
    "  ax2.set_ylabel('Accuracy')\n",
    "  ax2.grid(True)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs):\n",
    "  nn_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(num_nodes, activation='relu', input_shape=(7,)),\n",
    "      tf.keras.layers.Dense(num_nodes, activation='relu', input_shape=(4,)),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "  nn_model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "  history = nn_model.fit(\n",
    "    X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2\n",
    "  )\n",
    "  return nn_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/486\n",
      "4/4 [==============================] - 2s 128ms/step - loss: 0.6922 - accuracy: 0.5021 - val_loss: 0.6834 - val_accuracy: 0.5667\n",
      "Epoch 2/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6795 - accuracy: 0.5858 - val_loss: 0.6811 - val_accuracy: 0.5667\n",
      "Epoch 3/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6748 - accuracy: 0.5858 - val_loss: 0.6782 - val_accuracy: 0.5667\n",
      "Epoch 4/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6713 - accuracy: 0.5858 - val_loss: 0.6750 - val_accuracy: 0.5667\n",
      "Epoch 5/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6686 - accuracy: 0.5858 - val_loss: 0.6713 - val_accuracy: 0.5667\n",
      "Epoch 6/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6635 - accuracy: 0.5858 - val_loss: 0.6628 - val_accuracy: 0.5667\n",
      "Epoch 7/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6564 - accuracy: 0.5858 - val_loss: 0.6547 - val_accuracy: 0.5667\n",
      "Epoch 8/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6468 - accuracy: 0.5858 - val_loss: 0.6425 - val_accuracy: 0.5667\n",
      "Epoch 9/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6357 - accuracy: 0.5858 - val_loss: 0.6282 - val_accuracy: 0.5667\n",
      "Epoch 10/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6200 - accuracy: 0.5941 - val_loss: 0.6110 - val_accuracy: 0.5667\n",
      "Epoch 11/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6003 - accuracy: 0.6234 - val_loss: 0.5857 - val_accuracy: 0.6500\n",
      "Epoch 12/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5750 - accuracy: 0.7071 - val_loss: 0.5545 - val_accuracy: 0.7333\n",
      "Epoch 13/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5480 - accuracy: 0.7782 - val_loss: 0.5245 - val_accuracy: 0.7833\n",
      "Epoch 14/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5150 - accuracy: 0.8452 - val_loss: 0.4938 - val_accuracy: 0.7833\n",
      "Epoch 15/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4795 - accuracy: 0.8452 - val_loss: 0.4556 - val_accuracy: 0.7833\n",
      "Epoch 16/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4496 - accuracy: 0.8954 - val_loss: 0.4233 - val_accuracy: 0.8333\n",
      "Epoch 17/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4171 - accuracy: 0.8577 - val_loss: 0.4107 - val_accuracy: 0.8167\n",
      "Epoch 18/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3832 - accuracy: 0.9079 - val_loss: 0.3704 - val_accuracy: 0.8500\n",
      "Epoch 19/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3605 - accuracy: 0.9038 - val_loss: 0.3688 - val_accuracy: 0.8333\n",
      "Epoch 20/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3450 - accuracy: 0.8745 - val_loss: 0.3429 - val_accuracy: 0.8333\n",
      "Epoch 21/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3377 - accuracy: 0.8661 - val_loss: 0.3604 - val_accuracy: 0.7833\n",
      "Epoch 22/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2943 - accuracy: 0.9038 - val_loss: 0.3171 - val_accuracy: 0.8500\n",
      "Epoch 23/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3075 - accuracy: 0.8996 - val_loss: 0.3690 - val_accuracy: 0.8000\n",
      "Epoch 24/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2804 - accuracy: 0.9121 - val_loss: 0.3113 - val_accuracy: 0.8500\n",
      "Epoch 25/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2824 - accuracy: 0.8828 - val_loss: 0.3380 - val_accuracy: 0.8333\n",
      "Epoch 26/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2744 - accuracy: 0.8996 - val_loss: 0.3434 - val_accuracy: 0.8167\n",
      "Epoch 27/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2883 - accuracy: 0.8996 - val_loss: 0.3139 - val_accuracy: 0.8667\n",
      "Epoch 28/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2819 - accuracy: 0.8954 - val_loss: 0.3897 - val_accuracy: 0.8000\n",
      "Epoch 29/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2634 - accuracy: 0.8954 - val_loss: 0.3071 - val_accuracy: 0.8500\n",
      "Epoch 30/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2491 - accuracy: 0.9038 - val_loss: 0.3739 - val_accuracy: 0.8333\n",
      "Epoch 31/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2457 - accuracy: 0.9121 - val_loss: 0.3314 - val_accuracy: 0.8333\n",
      "Epoch 32/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2424 - accuracy: 0.9079 - val_loss: 0.3207 - val_accuracy: 0.8333\n",
      "Epoch 33/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2448 - accuracy: 0.9079 - val_loss: 0.3723 - val_accuracy: 0.8333\n",
      "Epoch 34/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2325 - accuracy: 0.9121 - val_loss: 0.3142 - val_accuracy: 0.8667\n",
      "Epoch 35/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2317 - accuracy: 0.9163 - val_loss: 0.3591 - val_accuracy: 0.8167\n",
      "Epoch 36/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2438 - accuracy: 0.9121 - val_loss: 0.3630 - val_accuracy: 0.8167\n",
      "Epoch 37/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2221 - accuracy: 0.9205 - val_loss: 0.3153 - val_accuracy: 0.8667\n",
      "Epoch 38/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2323 - accuracy: 0.9038 - val_loss: 0.3573 - val_accuracy: 0.8167\n",
      "Epoch 39/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2208 - accuracy: 0.9205 - val_loss: 0.3516 - val_accuracy: 0.8167\n",
      "Epoch 40/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2213 - accuracy: 0.9247 - val_loss: 0.3340 - val_accuracy: 0.8333\n",
      "Epoch 41/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2246 - accuracy: 0.9205 - val_loss: 0.3775 - val_accuracy: 0.8167\n",
      "Epoch 42/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2188 - accuracy: 0.9163 - val_loss: 0.3270 - val_accuracy: 0.8500\n",
      "Epoch 43/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2151 - accuracy: 0.9205 - val_loss: 0.3670 - val_accuracy: 0.8167\n",
      "Epoch 44/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2208 - accuracy: 0.9247 - val_loss: 0.3775 - val_accuracy: 0.8167\n",
      "Epoch 45/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2144 - accuracy: 0.9289 - val_loss: 0.3281 - val_accuracy: 0.8500\n",
      "Epoch 46/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2278 - accuracy: 0.9079 - val_loss: 0.3784 - val_accuracy: 0.8167\n",
      "Epoch 47/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2081 - accuracy: 0.9372 - val_loss: 0.3366 - val_accuracy: 0.8500\n",
      "Epoch 48/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2184 - accuracy: 0.9163 - val_loss: 0.3534 - val_accuracy: 0.8167\n",
      "Epoch 49/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2077 - accuracy: 0.9289 - val_loss: 0.3762 - val_accuracy: 0.8167\n",
      "Epoch 50/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2106 - accuracy: 0.9289 - val_loss: 0.3487 - val_accuracy: 0.8333\n",
      "Epoch 51/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2060 - accuracy: 0.9289 - val_loss: 0.3594 - val_accuracy: 0.8167\n",
      "Epoch 52/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2054 - accuracy: 0.9247 - val_loss: 0.3621 - val_accuracy: 0.8167\n",
      "Epoch 53/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2053 - accuracy: 0.9289 - val_loss: 0.3623 - val_accuracy: 0.8167\n",
      "Epoch 54/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2040 - accuracy: 0.9289 - val_loss: 0.3671 - val_accuracy: 0.8167\n",
      "Epoch 55/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2055 - accuracy: 0.9247 - val_loss: 0.3596 - val_accuracy: 0.8167\n",
      "Epoch 56/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2044 - accuracy: 0.9289 - val_loss: 0.3636 - val_accuracy: 0.8167\n",
      "Epoch 57/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2025 - accuracy: 0.9289 - val_loss: 0.3719 - val_accuracy: 0.8167\n",
      "Epoch 58/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2042 - accuracy: 0.9247 - val_loss: 0.3474 - val_accuracy: 0.8500\n",
      "Epoch 59/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2208 - accuracy: 0.9079 - val_loss: 0.3693 - val_accuracy: 0.8167\n",
      "Epoch 60/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2313 - accuracy: 0.8996 - val_loss: 0.3798 - val_accuracy: 0.8167\n",
      "Epoch 61/486\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2023 - accuracy: 0.9079 - val_loss: 0.3314 - val_accuracy: 0.8500\n",
      "Epoch 62/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2084 - accuracy: 0.8996 - val_loss: 0.4105 - val_accuracy: 0.8167\n",
      "Epoch 63/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2093 - accuracy: 0.9247 - val_loss: 0.3729 - val_accuracy: 0.8167\n",
      "Epoch 64/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2035 - accuracy: 0.9163 - val_loss: 0.3458 - val_accuracy: 0.8500\n",
      "Epoch 65/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1969 - accuracy: 0.9121 - val_loss: 0.3945 - val_accuracy: 0.8167\n",
      "Epoch 66/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2064 - accuracy: 0.9289 - val_loss: 0.3662 - val_accuracy: 0.8167\n",
      "Epoch 67/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2016 - accuracy: 0.9205 - val_loss: 0.3430 - val_accuracy: 0.8500\n",
      "Epoch 68/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2072 - accuracy: 0.9121 - val_loss: 0.4085 - val_accuracy: 0.8167\n",
      "Epoch 69/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2019 - accuracy: 0.9289 - val_loss: 0.3448 - val_accuracy: 0.8500\n",
      "Epoch 70/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2047 - accuracy: 0.9079 - val_loss: 0.3696 - val_accuracy: 0.8167\n",
      "Epoch 71/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1989 - accuracy: 0.9289 - val_loss: 0.3874 - val_accuracy: 0.8167\n",
      "Epoch 72/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1942 - accuracy: 0.9247 - val_loss: 0.3449 - val_accuracy: 0.8500\n",
      "Epoch 73/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2050 - accuracy: 0.9121 - val_loss: 0.3674 - val_accuracy: 0.8167\n",
      "Epoch 74/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2010 - accuracy: 0.9205 - val_loss: 0.3824 - val_accuracy: 0.8167\n",
      "Epoch 75/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2109 - accuracy: 0.9163 - val_loss: 0.3532 - val_accuracy: 0.8500\n",
      "Epoch 76/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1977 - accuracy: 0.9247 - val_loss: 0.4048 - val_accuracy: 0.8167\n",
      "Epoch 77/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1985 - accuracy: 0.9247 - val_loss: 0.3494 - val_accuracy: 0.8500\n",
      "Epoch 78/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2050 - accuracy: 0.9205 - val_loss: 0.3751 - val_accuracy: 0.8167\n",
      "Epoch 79/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1966 - accuracy: 0.9247 - val_loss: 0.3580 - val_accuracy: 0.8333\n",
      "Epoch 80/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2021 - accuracy: 0.9121 - val_loss: 0.3514 - val_accuracy: 0.8500\n",
      "Epoch 81/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2003 - accuracy: 0.9247 - val_loss: 0.4068 - val_accuracy: 0.8167\n",
      "Epoch 82/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2073 - accuracy: 0.9247 - val_loss: 0.3470 - val_accuracy: 0.8500\n",
      "Epoch 83/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1940 - accuracy: 0.9289 - val_loss: 0.4044 - val_accuracy: 0.8167\n",
      "Epoch 84/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1977 - accuracy: 0.9331 - val_loss: 0.3560 - val_accuracy: 0.8333\n",
      "Epoch 85/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1990 - accuracy: 0.9121 - val_loss: 0.3489 - val_accuracy: 0.8500\n",
      "Epoch 86/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2058 - accuracy: 0.9079 - val_loss: 0.4028 - val_accuracy: 0.8167\n",
      "Epoch 87/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1977 - accuracy: 0.9247 - val_loss: 0.3388 - val_accuracy: 0.8500\n",
      "Epoch 88/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1989 - accuracy: 0.9205 - val_loss: 0.4046 - val_accuracy: 0.8167\n",
      "Epoch 89/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2114 - accuracy: 0.9205 - val_loss: 0.3482 - val_accuracy: 0.8500\n",
      "Epoch 90/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2097 - accuracy: 0.9079 - val_loss: 0.3502 - val_accuracy: 0.8500\n",
      "Epoch 91/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1911 - accuracy: 0.9205 - val_loss: 0.3938 - val_accuracy: 0.8167\n",
      "Epoch 92/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1959 - accuracy: 0.9331 - val_loss: 0.3720 - val_accuracy: 0.8167\n",
      "Epoch 93/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1946 - accuracy: 0.9205 - val_loss: 0.3571 - val_accuracy: 0.8333\n",
      "Epoch 94/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1924 - accuracy: 0.9205 - val_loss: 0.3807 - val_accuracy: 0.8167\n",
      "Epoch 95/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2003 - accuracy: 0.9247 - val_loss: 0.3662 - val_accuracy: 0.8333\n",
      "Epoch 96/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2015 - accuracy: 0.9205 - val_loss: 0.3418 - val_accuracy: 0.8500\n",
      "Epoch 97/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2009 - accuracy: 0.9289 - val_loss: 0.4006 - val_accuracy: 0.8167\n",
      "Epoch 98/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1924 - accuracy: 0.9205 - val_loss: 0.3448 - val_accuracy: 0.8500\n",
      "Epoch 99/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1989 - accuracy: 0.8996 - val_loss: 0.3690 - val_accuracy: 0.8333\n",
      "Epoch 100/486\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1991 - accuracy: 0.9331 - val_loss: 0.3811 - val_accuracy: 0.8167\n",
      "Epoch 101/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1965 - accuracy: 0.9205 - val_loss: 0.3447 - val_accuracy: 0.8500\n",
      "Epoch 102/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1952 - accuracy: 0.9289 - val_loss: 0.4106 - val_accuracy: 0.8167\n",
      "Epoch 103/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2000 - accuracy: 0.9247 - val_loss: 0.3459 - val_accuracy: 0.8500\n",
      "Epoch 104/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1956 - accuracy: 0.9247 - val_loss: 0.3827 - val_accuracy: 0.8167\n",
      "Epoch 105/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2028 - accuracy: 0.9205 - val_loss: 0.3983 - val_accuracy: 0.8167\n",
      "Epoch 106/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1894 - accuracy: 0.9372 - val_loss: 0.3333 - val_accuracy: 0.8500\n",
      "Epoch 107/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2016 - accuracy: 0.9038 - val_loss: 0.3666 - val_accuracy: 0.8333\n",
      "Epoch 108/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1922 - accuracy: 0.9247 - val_loss: 0.3696 - val_accuracy: 0.8333\n",
      "Epoch 109/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1918 - accuracy: 0.9289 - val_loss: 0.3480 - val_accuracy: 0.8333\n",
      "Epoch 110/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1913 - accuracy: 0.9205 - val_loss: 0.3765 - val_accuracy: 0.8167\n",
      "Epoch 111/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1923 - accuracy: 0.9289 - val_loss: 0.3620 - val_accuracy: 0.8333\n",
      "Epoch 112/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1890 - accuracy: 0.9205 - val_loss: 0.3408 - val_accuracy: 0.8500\n",
      "Epoch 113/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1941 - accuracy: 0.9121 - val_loss: 0.3699 - val_accuracy: 0.8333\n",
      "Epoch 114/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1960 - accuracy: 0.9331 - val_loss: 0.3754 - val_accuracy: 0.8167\n",
      "Epoch 115/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2084 - accuracy: 0.9038 - val_loss: 0.3375 - val_accuracy: 0.8500\n",
      "Epoch 116/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1945 - accuracy: 0.9247 - val_loss: 0.3949 - val_accuracy: 0.8167\n",
      "Epoch 117/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1910 - accuracy: 0.9289 - val_loss: 0.3495 - val_accuracy: 0.8333\n",
      "Epoch 118/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1926 - accuracy: 0.9205 - val_loss: 0.3475 - val_accuracy: 0.8333\n",
      "Epoch 119/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1911 - accuracy: 0.9205 - val_loss: 0.3792 - val_accuracy: 0.8167\n",
      "Epoch 120/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1890 - accuracy: 0.9247 - val_loss: 0.3480 - val_accuracy: 0.8333\n",
      "Epoch 121/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1960 - accuracy: 0.9079 - val_loss: 0.3602 - val_accuracy: 0.8333\n",
      "Epoch 122/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1981 - accuracy: 0.9289 - val_loss: 0.3805 - val_accuracy: 0.8167\n",
      "Epoch 123/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2070 - accuracy: 0.9121 - val_loss: 0.3524 - val_accuracy: 0.8333\n",
      "Epoch 124/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1930 - accuracy: 0.9289 - val_loss: 0.3945 - val_accuracy: 0.8167\n",
      "Epoch 125/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1909 - accuracy: 0.9289 - val_loss: 0.3354 - val_accuracy: 0.8500\n",
      "Epoch 126/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2080 - accuracy: 0.9205 - val_loss: 0.3745 - val_accuracy: 0.8167\n",
      "Epoch 127/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1862 - accuracy: 0.9289 - val_loss: 0.3327 - val_accuracy: 0.8500\n",
      "Epoch 128/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1932 - accuracy: 0.9163 - val_loss: 0.3639 - val_accuracy: 0.8333\n",
      "Epoch 129/486\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1933 - accuracy: 0.9289 - val_loss: 0.3757 - val_accuracy: 0.8167\n",
      "Epoch 130/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2116 - accuracy: 0.9079 - val_loss: 0.3370 - val_accuracy: 0.8500\n",
      "Epoch 131/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1835 - accuracy: 0.9331 - val_loss: 0.4142 - val_accuracy: 0.8333\n",
      "Epoch 132/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2006 - accuracy: 0.9205 - val_loss: 0.3485 - val_accuracy: 0.8333\n",
      "Epoch 133/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1894 - accuracy: 0.9163 - val_loss: 0.3383 - val_accuracy: 0.8500\n",
      "Epoch 134/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1947 - accuracy: 0.9205 - val_loss: 0.3664 - val_accuracy: 0.8167\n",
      "Epoch 135/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1889 - accuracy: 0.9331 - val_loss: 0.3805 - val_accuracy: 0.8167\n",
      "Epoch 136/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1982 - accuracy: 0.9205 - val_loss: 0.3436 - val_accuracy: 0.8333\n",
      "Epoch 137/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1863 - accuracy: 0.9331 - val_loss: 0.3823 - val_accuracy: 0.8167\n",
      "Epoch 138/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2039 - accuracy: 0.9247 - val_loss: 0.3460 - val_accuracy: 0.8333\n",
      "Epoch 139/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1982 - accuracy: 0.9079 - val_loss: 0.3299 - val_accuracy: 0.8500\n",
      "Epoch 140/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2003 - accuracy: 0.9247 - val_loss: 0.3997 - val_accuracy: 0.8333\n",
      "Epoch 141/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1911 - accuracy: 0.9205 - val_loss: 0.3278 - val_accuracy: 0.8500\n",
      "Epoch 142/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1924 - accuracy: 0.9079 - val_loss: 0.3575 - val_accuracy: 0.8333\n",
      "Epoch 143/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1871 - accuracy: 0.9247 - val_loss: 0.3677 - val_accuracy: 0.8167\n",
      "Epoch 144/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1871 - accuracy: 0.9247 - val_loss: 0.3485 - val_accuracy: 0.8333\n",
      "Epoch 145/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2013 - accuracy: 0.9079 - val_loss: 0.3565 - val_accuracy: 0.8333\n",
      "Epoch 146/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1898 - accuracy: 0.9247 - val_loss: 0.3928 - val_accuracy: 0.8333\n",
      "Epoch 147/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1925 - accuracy: 0.9247 - val_loss: 0.3300 - val_accuracy: 0.8500\n",
      "Epoch 148/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1912 - accuracy: 0.9163 - val_loss: 0.3621 - val_accuracy: 0.8333\n",
      "Epoch 149/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1881 - accuracy: 0.9247 - val_loss: 0.3696 - val_accuracy: 0.8167\n",
      "Epoch 150/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1886 - accuracy: 0.9372 - val_loss: 0.3504 - val_accuracy: 0.8333\n",
      "Epoch 151/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1911 - accuracy: 0.9289 - val_loss: 0.3647 - val_accuracy: 0.8167\n",
      "Epoch 152/486\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1961 - accuracy: 0.9205 - val_loss: 0.3498 - val_accuracy: 0.8333\n",
      "Epoch 153/486\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1933 - accuracy: 0.9205 - val_loss: 0.3610 - val_accuracy: 0.8333\n",
      "Epoch 154/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1842 - accuracy: 0.9289 - val_loss: 0.3322 - val_accuracy: 0.8500\n",
      "Epoch 155/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1957 - accuracy: 0.9038 - val_loss: 0.3548 - val_accuracy: 0.8333\n",
      "Epoch 156/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2017 - accuracy: 0.9205 - val_loss: 0.4048 - val_accuracy: 0.8333\n",
      "Epoch 157/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1931 - accuracy: 0.9331 - val_loss: 0.3205 - val_accuracy: 0.8667\n",
      "Epoch 158/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1970 - accuracy: 0.9079 - val_loss: 0.3890 - val_accuracy: 0.8333\n",
      "Epoch 159/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1933 - accuracy: 0.9289 - val_loss: 0.3699 - val_accuracy: 0.8167\n",
      "Epoch 160/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1889 - accuracy: 0.9163 - val_loss: 0.3295 - val_accuracy: 0.8500\n",
      "Epoch 161/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1906 - accuracy: 0.9163 - val_loss: 0.3862 - val_accuracy: 0.8333\n",
      "Epoch 162/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1910 - accuracy: 0.9247 - val_loss: 0.3620 - val_accuracy: 0.8167\n",
      "Epoch 163/486\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1918 - accuracy: 0.9247 - val_loss: 0.3506 - val_accuracy: 0.8333\n",
      "Epoch 164/486\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1885 - accuracy: 0.9331 - val_loss: 0.3538 - val_accuracy: 0.8333\n",
      "Epoch 165/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1878 - accuracy: 0.9289 - val_loss: 0.3429 - val_accuracy: 0.8333\n",
      "Epoch 166/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1852 - accuracy: 0.9372 - val_loss: 0.3684 - val_accuracy: 0.8167\n",
      "Epoch 167/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1881 - accuracy: 0.9205 - val_loss: 0.3486 - val_accuracy: 0.8333\n",
      "Epoch 168/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1877 - accuracy: 0.9331 - val_loss: 0.3428 - val_accuracy: 0.8333\n",
      "Epoch 169/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1937 - accuracy: 0.9163 - val_loss: 0.3416 - val_accuracy: 0.8333\n",
      "Epoch 170/486\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1894 - accuracy: 0.9331 - val_loss: 0.3814 - val_accuracy: 0.8333\n",
      "Epoch 171/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1915 - accuracy: 0.9289 - val_loss: 0.3254 - val_accuracy: 0.8500\n",
      "Epoch 172/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1985 - accuracy: 0.9038 - val_loss: 0.3259 - val_accuracy: 0.8500\n",
      "Epoch 173/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2041 - accuracy: 0.8954 - val_loss: 0.4063 - val_accuracy: 0.8333\n",
      "Epoch 174/486\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2071 - accuracy: 0.9205 - val_loss: 0.3193 - val_accuracy: 0.8667\n",
      "Epoch 175/486\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1886 - accuracy: 0.9121 - val_loss: 0.3871 - val_accuracy: 0.8333\n",
      "Epoch 176/486\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2058 - accuracy: 0.9079 - val_loss: 0.3844 - val_accuracy: 0.8333\n",
      "Epoch 177/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1873 - accuracy: 0.9331 - val_loss: 0.3097 - val_accuracy: 0.8667\n",
      "Epoch 178/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2046 - accuracy: 0.9079 - val_loss: 0.3745 - val_accuracy: 0.8333\n",
      "Epoch 179/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2095 - accuracy: 0.9121 - val_loss: 0.3700 - val_accuracy: 0.8333\n",
      "Epoch 180/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1872 - accuracy: 0.9247 - val_loss: 0.3219 - val_accuracy: 0.8500\n",
      "Epoch 181/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1928 - accuracy: 0.9038 - val_loss: 0.3603 - val_accuracy: 0.8167\n",
      "Epoch 182/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1959 - accuracy: 0.9205 - val_loss: 0.3895 - val_accuracy: 0.8333\n",
      "Epoch 183/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1918 - accuracy: 0.9205 - val_loss: 0.3130 - val_accuracy: 0.8667\n",
      "Epoch 184/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1921 - accuracy: 0.9121 - val_loss: 0.3703 - val_accuracy: 0.8333\n",
      "Epoch 185/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1879 - accuracy: 0.9289 - val_loss: 0.3616 - val_accuracy: 0.8167\n",
      "Epoch 186/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1874 - accuracy: 0.9247 - val_loss: 0.3284 - val_accuracy: 0.8500\n",
      "Epoch 187/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1852 - accuracy: 0.9205 - val_loss: 0.3609 - val_accuracy: 0.8167\n",
      "Epoch 188/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1890 - accuracy: 0.9247 - val_loss: 0.3517 - val_accuracy: 0.8333\n",
      "Epoch 189/486\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1897 - accuracy: 0.9289 - val_loss: 0.3356 - val_accuracy: 0.8333\n",
      "Epoch 190/486\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1860 - accuracy: 0.9331 - val_loss: 0.3537 - val_accuracy: 0.8333\n",
      "Epoch 191/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1846 - accuracy: 0.9289 - val_loss: 0.3725 - val_accuracy: 0.8333\n",
      "Epoch 192/486\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1869 - accuracy: 0.9372 - val_loss: 0.3379 - val_accuracy: 0.8333\n",
      "Epoch 193/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1865 - accuracy: 0.9289 - val_loss: 0.3478 - val_accuracy: 0.8333\n",
      "Epoch 194/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1837 - accuracy: 0.9289 - val_loss: 0.3669 - val_accuracy: 0.8333\n",
      "Epoch 195/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1985 - accuracy: 0.9205 - val_loss: 0.3372 - val_accuracy: 0.8333\n",
      "Epoch 196/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1885 - accuracy: 0.9163 - val_loss: 0.3289 - val_accuracy: 0.8500\n",
      "Epoch 197/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1879 - accuracy: 0.9372 - val_loss: 0.3853 - val_accuracy: 0.8333\n",
      "Epoch 198/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1882 - accuracy: 0.9247 - val_loss: 0.3292 - val_accuracy: 0.8500\n",
      "Epoch 199/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1867 - accuracy: 0.9163 - val_loss: 0.3507 - val_accuracy: 0.8333\n",
      "Epoch 200/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1894 - accuracy: 0.9289 - val_loss: 0.3573 - val_accuracy: 0.8167\n",
      "Epoch 201/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1816 - accuracy: 0.9372 - val_loss: 0.3220 - val_accuracy: 0.8500\n",
      "Epoch 202/486\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1898 - accuracy: 0.9163 - val_loss: 0.3405 - val_accuracy: 0.8333\n",
      "Epoch 203/486\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1926 - accuracy: 0.9331 - val_loss: 0.3604 - val_accuracy: 0.8333\n",
      "Epoch 204/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1915 - accuracy: 0.9121 - val_loss: 0.3181 - val_accuracy: 0.8667\n",
      "Epoch 205/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1954 - accuracy: 0.9079 - val_loss: 0.3903 - val_accuracy: 0.8333\n",
      "Epoch 206/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1853 - accuracy: 0.9331 - val_loss: 0.3225 - val_accuracy: 0.8500\n",
      "Epoch 207/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1942 - accuracy: 0.9079 - val_loss: 0.3266 - val_accuracy: 0.8500\n",
      "Epoch 208/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1822 - accuracy: 0.9331 - val_loss: 0.3945 - val_accuracy: 0.8333\n",
      "Epoch 209/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1936 - accuracy: 0.9121 - val_loss: 0.3269 - val_accuracy: 0.8500\n",
      "Epoch 210/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1886 - accuracy: 0.9121 - val_loss: 0.3165 - val_accuracy: 0.8667\n",
      "Epoch 211/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1881 - accuracy: 0.9247 - val_loss: 0.3754 - val_accuracy: 0.8333\n",
      "Epoch 212/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1874 - accuracy: 0.9289 - val_loss: 0.3367 - val_accuracy: 0.8333\n",
      "Epoch 213/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1936 - accuracy: 0.9163 - val_loss: 0.3177 - val_accuracy: 0.8667\n",
      "Epoch 214/486\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2003 - accuracy: 0.9163 - val_loss: 0.3901 - val_accuracy: 0.8333\n",
      "Epoch 215/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1866 - accuracy: 0.9372 - val_loss: 0.3150 - val_accuracy: 0.8667\n",
      "Epoch 216/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1932 - accuracy: 0.9205 - val_loss: 0.3475 - val_accuracy: 0.8333\n",
      "Epoch 217/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1843 - accuracy: 0.9372 - val_loss: 0.3392 - val_accuracy: 0.8333\n",
      "Epoch 218/486\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1855 - accuracy: 0.9372 - val_loss: 0.3453 - val_accuracy: 0.8333\n",
      "Epoch 219/486\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1864 - accuracy: 0.9247 - val_loss: 0.3318 - val_accuracy: 0.8333\n",
      "Epoch 220/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1867 - accuracy: 0.9331 - val_loss: 0.3772 - val_accuracy: 0.8333\n",
      "Epoch 221/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1874 - accuracy: 0.9331 - val_loss: 0.3246 - val_accuracy: 0.8500\n",
      "Epoch 222/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1895 - accuracy: 0.9247 - val_loss: 0.3325 - val_accuracy: 0.8333\n",
      "Epoch 223/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1953 - accuracy: 0.9247 - val_loss: 0.3646 - val_accuracy: 0.8333\n",
      "Epoch 224/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1864 - accuracy: 0.9331 - val_loss: 0.3099 - val_accuracy: 0.8667\n",
      "Epoch 225/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1954 - accuracy: 0.9205 - val_loss: 0.3704 - val_accuracy: 0.8333\n",
      "Epoch 226/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1847 - accuracy: 0.9372 - val_loss: 0.3282 - val_accuracy: 0.8333\n",
      "Epoch 227/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1916 - accuracy: 0.9121 - val_loss: 0.3303 - val_accuracy: 0.8333\n",
      "Epoch 228/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1890 - accuracy: 0.9331 - val_loss: 0.3741 - val_accuracy: 0.8333\n",
      "Epoch 229/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1885 - accuracy: 0.9372 - val_loss: 0.3208 - val_accuracy: 0.8500\n",
      "Epoch 230/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1928 - accuracy: 0.9205 - val_loss: 0.3454 - val_accuracy: 0.8500\n",
      "Epoch 231/486\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1879 - accuracy: 0.9247 - val_loss: 0.3131 - val_accuracy: 0.8667\n",
      "Epoch 232/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1883 - accuracy: 0.9205 - val_loss: 0.3438 - val_accuracy: 0.8500\n",
      "Epoch 233/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1850 - accuracy: 0.9372 - val_loss: 0.3497 - val_accuracy: 0.8333\n",
      "Epoch 234/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1868 - accuracy: 0.9247 - val_loss: 0.3418 - val_accuracy: 0.8333\n",
      "Epoch 235/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1817 - accuracy: 0.9372 - val_loss: 0.3191 - val_accuracy: 0.8500\n",
      "Epoch 236/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1884 - accuracy: 0.9079 - val_loss: 0.3361 - val_accuracy: 0.8333\n",
      "Epoch 237/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1917 - accuracy: 0.9289 - val_loss: 0.3794 - val_accuracy: 0.8333\n",
      "Epoch 238/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1929 - accuracy: 0.9121 - val_loss: 0.3123 - val_accuracy: 0.8667\n",
      "Epoch 239/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1852 - accuracy: 0.9205 - val_loss: 0.3743 - val_accuracy: 0.8333\n",
      "Epoch 240/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1881 - accuracy: 0.9331 - val_loss: 0.3380 - val_accuracy: 0.8333\n",
      "Epoch 241/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1839 - accuracy: 0.9331 - val_loss: 0.3289 - val_accuracy: 0.8333\n",
      "Epoch 242/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1878 - accuracy: 0.9247 - val_loss: 0.3420 - val_accuracy: 0.8500\n",
      "Epoch 243/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1834 - accuracy: 0.9372 - val_loss: 0.3283 - val_accuracy: 0.8333\n",
      "Epoch 244/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1854 - accuracy: 0.9247 - val_loss: 0.3354 - val_accuracy: 0.8333\n",
      "Epoch 245/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2004 - accuracy: 0.9289 - val_loss: 0.3499 - val_accuracy: 0.8333\n",
      "Epoch 246/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1904 - accuracy: 0.9205 - val_loss: 0.3091 - val_accuracy: 0.8667\n",
      "Epoch 247/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1907 - accuracy: 0.9331 - val_loss: 0.3671 - val_accuracy: 0.8333\n",
      "Epoch 248/486\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1945 - accuracy: 0.9247 - val_loss: 0.3267 - val_accuracy: 0.8333\n",
      "Epoch 249/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1817 - accuracy: 0.9372 - val_loss: 0.3589 - val_accuracy: 0.8333\n",
      "Epoch 250/486\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1851 - accuracy: 0.9331 - val_loss: 0.3361 - val_accuracy: 0.8333\n",
      "Epoch 251/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1827 - accuracy: 0.9372 - val_loss: 0.3246 - val_accuracy: 0.8333\n",
      "Epoch 252/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1839 - accuracy: 0.9331 - val_loss: 0.3346 - val_accuracy: 0.8333\n",
      "Epoch 253/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1858 - accuracy: 0.9331 - val_loss: 0.3345 - val_accuracy: 0.8333\n",
      "Epoch 254/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1850 - accuracy: 0.9289 - val_loss: 0.3182 - val_accuracy: 0.8500\n",
      "Epoch 255/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1910 - accuracy: 0.9289 - val_loss: 0.3609 - val_accuracy: 0.8333\n",
      "Epoch 256/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1895 - accuracy: 0.9205 - val_loss: 0.3205 - val_accuracy: 0.8500\n",
      "Epoch 257/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1838 - accuracy: 0.9372 - val_loss: 0.3622 - val_accuracy: 0.8333\n",
      "Epoch 258/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1846 - accuracy: 0.9289 - val_loss: 0.3296 - val_accuracy: 0.8333\n",
      "Epoch 259/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1931 - accuracy: 0.9079 - val_loss: 0.3194 - val_accuracy: 0.8500\n",
      "Epoch 260/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1929 - accuracy: 0.9414 - val_loss: 0.3721 - val_accuracy: 0.8333\n",
      "Epoch 261/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1896 - accuracy: 0.9163 - val_loss: 0.3062 - val_accuracy: 0.8667\n",
      "Epoch 262/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1877 - accuracy: 0.9121 - val_loss: 0.3638 - val_accuracy: 0.8333\n",
      "Epoch 263/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1967 - accuracy: 0.9289 - val_loss: 0.3506 - val_accuracy: 0.8333\n",
      "Epoch 264/486\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2041 - accuracy: 0.9079 - val_loss: 0.3062 - val_accuracy: 0.8667\n",
      "Epoch 265/486\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1912 - accuracy: 0.9079 - val_loss: 0.4313 - val_accuracy: 0.8500\n",
      "Epoch 266/486\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1994 - accuracy: 0.9205 - val_loss: 0.3079 - val_accuracy: 0.8667\n",
      "Epoch 267/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2066 - accuracy: 0.9038 - val_loss: 0.3171 - val_accuracy: 0.8500\n",
      "Epoch 268/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2117 - accuracy: 0.9247 - val_loss: 0.4046 - val_accuracy: 0.8333\n",
      "Epoch 269/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2026 - accuracy: 0.9121 - val_loss: 0.2974 - val_accuracy: 0.8667\n",
      "Epoch 270/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1911 - accuracy: 0.9121 - val_loss: 0.3671 - val_accuracy: 0.8333\n",
      "Epoch 271/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2130 - accuracy: 0.9163 - val_loss: 0.3442 - val_accuracy: 0.8333\n",
      "Epoch 272/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1959 - accuracy: 0.9163 - val_loss: 0.2916 - val_accuracy: 0.9000\n",
      "Epoch 273/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1980 - accuracy: 0.9247 - val_loss: 0.3889 - val_accuracy: 0.8333\n",
      "Epoch 274/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1938 - accuracy: 0.9289 - val_loss: 0.3330 - val_accuracy: 0.8500\n",
      "Epoch 275/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1863 - accuracy: 0.9205 - val_loss: 0.3055 - val_accuracy: 0.8667\n",
      "Epoch 276/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1906 - accuracy: 0.9331 - val_loss: 0.3543 - val_accuracy: 0.8333\n",
      "Epoch 277/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1893 - accuracy: 0.9247 - val_loss: 0.3199 - val_accuracy: 0.8500\n",
      "Epoch 278/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1840 - accuracy: 0.9414 - val_loss: 0.3550 - val_accuracy: 0.8333\n",
      "Epoch 279/486\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1886 - accuracy: 0.9331 - val_loss: 0.3205 - val_accuracy: 0.8500\n",
      "Epoch 280/486\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1860 - accuracy: 0.9205 - val_loss: 0.3385 - val_accuracy: 0.8500\n",
      "Epoch 281/486\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1847 - accuracy: 0.9372 - val_loss: 0.3160 - val_accuracy: 0.8500\n",
      "Epoch 282/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1881 - accuracy: 0.9331 - val_loss: 0.3497 - val_accuracy: 0.8333\n",
      "Epoch 283/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1832 - accuracy: 0.9331 - val_loss: 0.3147 - val_accuracy: 0.8500\n",
      "Epoch 284/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1884 - accuracy: 0.9247 - val_loss: 0.3430 - val_accuracy: 0.8333\n",
      "Epoch 285/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1867 - accuracy: 0.9289 - val_loss: 0.3159 - val_accuracy: 0.8500\n",
      "Epoch 286/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1909 - accuracy: 0.9372 - val_loss: 0.3568 - val_accuracy: 0.8333\n",
      "Epoch 287/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1831 - accuracy: 0.9414 - val_loss: 0.3094 - val_accuracy: 0.8667\n",
      "Epoch 288/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1848 - accuracy: 0.9331 - val_loss: 0.3392 - val_accuracy: 0.8500\n",
      "Epoch 289/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1832 - accuracy: 0.9289 - val_loss: 0.3458 - val_accuracy: 0.8333\n",
      "Epoch 290/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1852 - accuracy: 0.9289 - val_loss: 0.3142 - val_accuracy: 0.8500\n",
      "Epoch 291/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1850 - accuracy: 0.9247 - val_loss: 0.3240 - val_accuracy: 0.8500\n",
      "Epoch 292/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1830 - accuracy: 0.9289 - val_loss: 0.3412 - val_accuracy: 0.8333\n",
      "Epoch 293/486\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1847 - accuracy: 0.9289 - val_loss: 0.3537 - val_accuracy: 0.8333\n",
      "Epoch 294/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1913 - accuracy: 0.9205 - val_loss: 0.3153 - val_accuracy: 0.8500\n",
      "Epoch 295/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1886 - accuracy: 0.9372 - val_loss: 0.3716 - val_accuracy: 0.8333\n",
      "Epoch 296/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1845 - accuracy: 0.9414 - val_loss: 0.3098 - val_accuracy: 0.8667\n",
      "Epoch 297/486\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1866 - accuracy: 0.9121 - val_loss: 0.3299 - val_accuracy: 0.8500\n",
      "Epoch 298/486\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1954 - accuracy: 0.9331 - val_loss: 0.3393 - val_accuracy: 0.8500\n",
      "Epoch 299/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1780 - accuracy: 0.9372 - val_loss: 0.3045 - val_accuracy: 0.8667\n",
      "Epoch 300/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2036 - accuracy: 0.9038 - val_loss: 0.3216 - val_accuracy: 0.8500\n",
      "Epoch 301/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1860 - accuracy: 0.9289 - val_loss: 0.3737 - val_accuracy: 0.8333\n",
      "Epoch 302/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1834 - accuracy: 0.9289 - val_loss: 0.3078 - val_accuracy: 0.8667\n",
      "Epoch 303/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1885 - accuracy: 0.9163 - val_loss: 0.3240 - val_accuracy: 0.8500\n",
      "Epoch 304/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1916 - accuracy: 0.9289 - val_loss: 0.3558 - val_accuracy: 0.8333\n",
      "Epoch 305/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1842 - accuracy: 0.9289 - val_loss: 0.3058 - val_accuracy: 0.8667\n",
      "Epoch 306/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1960 - accuracy: 0.9079 - val_loss: 0.3324 - val_accuracy: 0.8500\n",
      "Epoch 307/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1891 - accuracy: 0.9247 - val_loss: 0.3501 - val_accuracy: 0.8333\n",
      "Epoch 308/486\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1876 - accuracy: 0.9289 - val_loss: 0.3208 - val_accuracy: 0.8500\n",
      "Epoch 309/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1882 - accuracy: 0.9247 - val_loss: 0.3491 - val_accuracy: 0.8333\n",
      "Epoch 310/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1801 - accuracy: 0.9372 - val_loss: 0.3064 - val_accuracy: 0.8667\n",
      "Epoch 311/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1917 - accuracy: 0.9079 - val_loss: 0.3296 - val_accuracy: 0.8500\n",
      "Epoch 312/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1923 - accuracy: 0.9079 - val_loss: 0.3668 - val_accuracy: 0.8333\n",
      "Epoch 313/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1853 - accuracy: 0.9247 - val_loss: 0.3038 - val_accuracy: 0.8667\n",
      "Epoch 314/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1908 - accuracy: 0.9121 - val_loss: 0.3453 - val_accuracy: 0.8333\n",
      "Epoch 315/486\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1857 - accuracy: 0.9331 - val_loss: 0.3180 - val_accuracy: 0.8667\n",
      "Epoch 316/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1825 - accuracy: 0.9289 - val_loss: 0.3370 - val_accuracy: 0.8500\n",
      "Epoch 317/486\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1891 - accuracy: 0.9247 - val_loss: 0.3592 - val_accuracy: 0.8333\n",
      "Epoch 318/486\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1882 - accuracy: 0.9163 - val_loss: 0.2980 - val_accuracy: 0.8667\n",
      "Epoch 319/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1964 - accuracy: 0.9079 - val_loss: 0.3547 - val_accuracy: 0.8333\n",
      "Epoch 320/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1835 - accuracy: 0.9331 - val_loss: 0.3166 - val_accuracy: 0.8667\n",
      "Epoch 321/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1850 - accuracy: 0.9247 - val_loss: 0.3190 - val_accuracy: 0.8667\n",
      "Epoch 322/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1828 - accuracy: 0.9289 - val_loss: 0.3425 - val_accuracy: 0.8333\n",
      "Epoch 323/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1905 - accuracy: 0.9372 - val_loss: 0.3327 - val_accuracy: 0.8500\n",
      "Epoch 324/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1850 - accuracy: 0.9289 - val_loss: 0.2960 - val_accuracy: 0.8667\n",
      "Epoch 325/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1906 - accuracy: 0.9289 - val_loss: 0.3545 - val_accuracy: 0.8333\n",
      "Epoch 326/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1875 - accuracy: 0.9331 - val_loss: 0.3307 - val_accuracy: 0.8500\n",
      "Epoch 327/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1802 - accuracy: 0.9247 - val_loss: 0.3017 - val_accuracy: 0.8667\n",
      "Epoch 328/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1934 - accuracy: 0.9163 - val_loss: 0.3492 - val_accuracy: 0.8333\n",
      "Epoch 329/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1814 - accuracy: 0.9372 - val_loss: 0.3172 - val_accuracy: 0.8667\n",
      "Epoch 330/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1845 - accuracy: 0.9163 - val_loss: 0.3101 - val_accuracy: 0.8667\n",
      "Epoch 331/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1841 - accuracy: 0.9331 - val_loss: 0.3441 - val_accuracy: 0.8333\n",
      "Epoch 332/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1828 - accuracy: 0.9414 - val_loss: 0.3277 - val_accuracy: 0.8500\n",
      "Epoch 333/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1820 - accuracy: 0.9289 - val_loss: 0.3229 - val_accuracy: 0.8500\n",
      "Epoch 334/486\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1828 - accuracy: 0.9331 - val_loss: 0.3340 - val_accuracy: 0.8500\n",
      "Epoch 335/486\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2060 - accuracy: 0.9121 - val_loss: 0.3508 - val_accuracy: 0.8333\n",
      "Epoch 336/486\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1826 - accuracy: 0.9079 - val_loss: 0.2935 - val_accuracy: 0.8667\n",
      "Epoch 337/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1963 - accuracy: 0.9038 - val_loss: 0.3474 - val_accuracy: 0.8333\n",
      "Epoch 338/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1888 - accuracy: 0.9289 - val_loss: 0.3442 - val_accuracy: 0.8333\n",
      "Epoch 339/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1825 - accuracy: 0.9372 - val_loss: 0.3288 - val_accuracy: 0.8500\n",
      "Epoch 340/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1811 - accuracy: 0.9372 - val_loss: 0.3243 - val_accuracy: 0.8500\n",
      "Epoch 341/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1865 - accuracy: 0.9247 - val_loss: 0.3190 - val_accuracy: 0.8500\n",
      "Epoch 342/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1931 - accuracy: 0.9331 - val_loss: 0.3558 - val_accuracy: 0.8333\n",
      "Epoch 343/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1911 - accuracy: 0.9289 - val_loss: 0.3076 - val_accuracy: 0.8667\n",
      "Epoch 344/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1851 - accuracy: 0.9289 - val_loss: 0.3519 - val_accuracy: 0.8333\n",
      "Epoch 345/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1835 - accuracy: 0.9247 - val_loss: 0.3225 - val_accuracy: 0.8500\n",
      "Epoch 346/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1868 - accuracy: 0.9205 - val_loss: 0.3222 - val_accuracy: 0.8500\n",
      "Epoch 347/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1800 - accuracy: 0.9331 - val_loss: 0.3651 - val_accuracy: 0.8333\n",
      "Epoch 348/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1846 - accuracy: 0.9331 - val_loss: 0.3173 - val_accuracy: 0.8667\n",
      "Epoch 349/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1904 - accuracy: 0.9038 - val_loss: 0.3165 - val_accuracy: 0.8667\n",
      "Epoch 350/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1862 - accuracy: 0.9205 - val_loss: 0.3634 - val_accuracy: 0.8333\n",
      "Epoch 351/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1817 - accuracy: 0.9372 - val_loss: 0.2997 - val_accuracy: 0.8667\n",
      "Epoch 352/486\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1905 - accuracy: 0.9163 - val_loss: 0.3287 - val_accuracy: 0.8500\n",
      "Epoch 353/486\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1831 - accuracy: 0.9372 - val_loss: 0.3211 - val_accuracy: 0.8500\n",
      "Epoch 354/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1846 - accuracy: 0.9247 - val_loss: 0.3385 - val_accuracy: 0.8333\n",
      "Epoch 355/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1866 - accuracy: 0.9289 - val_loss: 0.3111 - val_accuracy: 0.8667\n",
      "Epoch 356/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1811 - accuracy: 0.9331 - val_loss: 0.3515 - val_accuracy: 0.8333\n",
      "Epoch 357/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1907 - accuracy: 0.9289 - val_loss: 0.3253 - val_accuracy: 0.8500\n",
      "Epoch 358/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1819 - accuracy: 0.9289 - val_loss: 0.3212 - val_accuracy: 0.8500\n",
      "Epoch 359/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1821 - accuracy: 0.9414 - val_loss: 0.3408 - val_accuracy: 0.8333\n",
      "Epoch 360/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1804 - accuracy: 0.9414 - val_loss: 0.3133 - val_accuracy: 0.8667\n",
      "Epoch 361/486\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1825 - accuracy: 0.9289 - val_loss: 0.3187 - val_accuracy: 0.8500\n",
      "Epoch 362/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1872 - accuracy: 0.9331 - val_loss: 0.3421 - val_accuracy: 0.8333\n",
      "Epoch 363/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1803 - accuracy: 0.9414 - val_loss: 0.3119 - val_accuracy: 0.8667\n",
      "Epoch 364/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1824 - accuracy: 0.9289 - val_loss: 0.3110 - val_accuracy: 0.8667\n",
      "Epoch 365/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1818 - accuracy: 0.9331 - val_loss: 0.3373 - val_accuracy: 0.8333\n",
      "Epoch 366/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1817 - accuracy: 0.9414 - val_loss: 0.3381 - val_accuracy: 0.8333\n",
      "Epoch 367/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1806 - accuracy: 0.9414 - val_loss: 0.3195 - val_accuracy: 0.8500\n",
      "Epoch 368/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1872 - accuracy: 0.9372 - val_loss: 0.3169 - val_accuracy: 0.8500\n",
      "Epoch 369/486\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1844 - accuracy: 0.9289 - val_loss: 0.3230 - val_accuracy: 0.8500\n",
      "Epoch 370/486\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1826 - accuracy: 0.9289 - val_loss: 0.3180 - val_accuracy: 0.8500\n",
      "Epoch 371/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1808 - accuracy: 0.9414 - val_loss: 0.3466 - val_accuracy: 0.8333\n",
      "Epoch 372/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1853 - accuracy: 0.9414 - val_loss: 0.3152 - val_accuracy: 0.8667\n",
      "Epoch 373/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1831 - accuracy: 0.9414 - val_loss: 0.3360 - val_accuracy: 0.8500\n",
      "Epoch 374/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1825 - accuracy: 0.9331 - val_loss: 0.3222 - val_accuracy: 0.8500\n",
      "Epoch 375/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1923 - accuracy: 0.9121 - val_loss: 0.3111 - val_accuracy: 0.8667\n",
      "Epoch 376/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1859 - accuracy: 0.9372 - val_loss: 0.3713 - val_accuracy: 0.8333\n",
      "Epoch 377/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1883 - accuracy: 0.9372 - val_loss: 0.3007 - val_accuracy: 0.8667\n",
      "Epoch 378/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1946 - accuracy: 0.9331 - val_loss: 0.3354 - val_accuracy: 0.8500\n",
      "Epoch 379/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1798 - accuracy: 0.9414 - val_loss: 0.3126 - val_accuracy: 0.8667\n",
      "Epoch 380/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1827 - accuracy: 0.9289 - val_loss: 0.3216 - val_accuracy: 0.8500\n",
      "Epoch 381/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1815 - accuracy: 0.9372 - val_loss: 0.3186 - val_accuracy: 0.8500\n",
      "Epoch 382/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1812 - accuracy: 0.9289 - val_loss: 0.3175 - val_accuracy: 0.8500\n",
      "Epoch 383/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1810 - accuracy: 0.9372 - val_loss: 0.3367 - val_accuracy: 0.8333\n",
      "Epoch 384/486\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1844 - accuracy: 0.9372 - val_loss: 0.3259 - val_accuracy: 0.8500\n",
      "Epoch 385/486\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1872 - accuracy: 0.9289 - val_loss: 0.3436 - val_accuracy: 0.8333\n",
      "Epoch 386/486\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1940 - accuracy: 0.9205 - val_loss: 0.2940 - val_accuracy: 0.8667\n",
      "Epoch 387/486\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1893 - accuracy: 0.9247 - val_loss: 0.3737 - val_accuracy: 0.8333\n",
      "Epoch 388/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1852 - accuracy: 0.9289 - val_loss: 0.3088 - val_accuracy: 0.8667\n",
      "Epoch 389/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1859 - accuracy: 0.9205 - val_loss: 0.3124 - val_accuracy: 0.8667\n",
      "Epoch 390/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1819 - accuracy: 0.9331 - val_loss: 0.3298 - val_accuracy: 0.8500\n",
      "Epoch 391/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1842 - accuracy: 0.9289 - val_loss: 0.3211 - val_accuracy: 0.8500\n",
      "Epoch 392/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1899 - accuracy: 0.9289 - val_loss: 0.3419 - val_accuracy: 0.8333\n",
      "Epoch 393/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1885 - accuracy: 0.9331 - val_loss: 0.2929 - val_accuracy: 0.8667\n",
      "Epoch 394/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1951 - accuracy: 0.9289 - val_loss: 0.3573 - val_accuracy: 0.8333\n",
      "Epoch 395/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1803 - accuracy: 0.9372 - val_loss: 0.3001 - val_accuracy: 0.8667\n",
      "Epoch 396/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1871 - accuracy: 0.9163 - val_loss: 0.3095 - val_accuracy: 0.8667\n",
      "Epoch 397/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1823 - accuracy: 0.9205 - val_loss: 0.3167 - val_accuracy: 0.8500\n",
      "Epoch 398/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1860 - accuracy: 0.9331 - val_loss: 0.3484 - val_accuracy: 0.8333\n",
      "Epoch 399/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1824 - accuracy: 0.9247 - val_loss: 0.3067 - val_accuracy: 0.8667\n",
      "Epoch 400/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1846 - accuracy: 0.9331 - val_loss: 0.3207 - val_accuracy: 0.8500\n",
      "Epoch 401/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1844 - accuracy: 0.9372 - val_loss: 0.3083 - val_accuracy: 0.8667\n",
      "Epoch 402/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1944 - accuracy: 0.9079 - val_loss: 0.3134 - val_accuracy: 0.8500\n",
      "Epoch 403/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1806 - accuracy: 0.9331 - val_loss: 0.3895 - val_accuracy: 0.8333\n",
      "Epoch 404/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1876 - accuracy: 0.9414 - val_loss: 0.3055 - val_accuracy: 0.8667\n",
      "Epoch 405/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1850 - accuracy: 0.9121 - val_loss: 0.3056 - val_accuracy: 0.8667\n",
      "Epoch 406/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1811 - accuracy: 0.9289 - val_loss: 0.3394 - val_accuracy: 0.8333\n",
      "Epoch 407/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1842 - accuracy: 0.9247 - val_loss: 0.3239 - val_accuracy: 0.8500\n",
      "Epoch 408/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1791 - accuracy: 0.9247 - val_loss: 0.2960 - val_accuracy: 0.8667\n",
      "Epoch 409/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1856 - accuracy: 0.9247 - val_loss: 0.3264 - val_accuracy: 0.8500\n",
      "Epoch 410/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1830 - accuracy: 0.9331 - val_loss: 0.3234 - val_accuracy: 0.8500\n",
      "Epoch 411/486\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1800 - accuracy: 0.9414 - val_loss: 0.3438 - val_accuracy: 0.8333\n",
      "Epoch 412/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1868 - accuracy: 0.9289 - val_loss: 0.3323 - val_accuracy: 0.8500\n",
      "Epoch 413/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2050 - accuracy: 0.9121 - val_loss: 0.3000 - val_accuracy: 0.8667\n",
      "Epoch 414/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1790 - accuracy: 0.9331 - val_loss: 0.3553 - val_accuracy: 0.8333\n",
      "Epoch 415/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1977 - accuracy: 0.9121 - val_loss: 0.3173 - val_accuracy: 0.8500\n",
      "Epoch 416/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1942 - accuracy: 0.9079 - val_loss: 0.2923 - val_accuracy: 0.8667\n",
      "Epoch 417/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1789 - accuracy: 0.9247 - val_loss: 0.3699 - val_accuracy: 0.8333\n",
      "Epoch 418/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1907 - accuracy: 0.9289 - val_loss: 0.3240 - val_accuracy: 0.8500\n",
      "Epoch 419/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1968 - accuracy: 0.9331 - val_loss: 0.2913 - val_accuracy: 0.8667\n",
      "Epoch 420/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1799 - accuracy: 0.9331 - val_loss: 0.3923 - val_accuracy: 0.8333\n",
      "Epoch 421/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1942 - accuracy: 0.9289 - val_loss: 0.3127 - val_accuracy: 0.8500\n",
      "Epoch 422/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1937 - accuracy: 0.9079 - val_loss: 0.2962 - val_accuracy: 0.8667\n",
      "Epoch 423/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1785 - accuracy: 0.9331 - val_loss: 0.3799 - val_accuracy: 0.8500\n",
      "Epoch 424/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1994 - accuracy: 0.9331 - val_loss: 0.3117 - val_accuracy: 0.8667\n",
      "Epoch 425/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1818 - accuracy: 0.9372 - val_loss: 0.3364 - val_accuracy: 0.8333\n",
      "Epoch 426/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1840 - accuracy: 0.9289 - val_loss: 0.3091 - val_accuracy: 0.8667\n",
      "Epoch 427/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1806 - accuracy: 0.9289 - val_loss: 0.3353 - val_accuracy: 0.8333\n",
      "Epoch 428/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1826 - accuracy: 0.9372 - val_loss: 0.3391 - val_accuracy: 0.8333\n",
      "Epoch 429/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1843 - accuracy: 0.9414 - val_loss: 0.3181 - val_accuracy: 0.8500\n",
      "Epoch 430/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1837 - accuracy: 0.9414 - val_loss: 0.3156 - val_accuracy: 0.8500\n",
      "Epoch 431/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1842 - accuracy: 0.9331 - val_loss: 0.3272 - val_accuracy: 0.8500\n",
      "Epoch 432/486\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1808 - accuracy: 0.9414 - val_loss: 0.3135 - val_accuracy: 0.8500\n",
      "Epoch 433/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1860 - accuracy: 0.9205 - val_loss: 0.3138 - val_accuracy: 0.8500\n",
      "Epoch 434/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1812 - accuracy: 0.9372 - val_loss: 0.3386 - val_accuracy: 0.8333\n",
      "Epoch 435/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1839 - accuracy: 0.9331 - val_loss: 0.3107 - val_accuracy: 0.8500\n",
      "Epoch 436/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1805 - accuracy: 0.9372 - val_loss: 0.3307 - val_accuracy: 0.8500\n",
      "Epoch 437/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1821 - accuracy: 0.9331 - val_loss: 0.3203 - val_accuracy: 0.8500\n",
      "Epoch 438/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1823 - accuracy: 0.9414 - val_loss: 0.3222 - val_accuracy: 0.8500\n",
      "Epoch 439/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1818 - accuracy: 0.9331 - val_loss: 0.3014 - val_accuracy: 0.8833\n",
      "Epoch 440/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1803 - accuracy: 0.9289 - val_loss: 0.3442 - val_accuracy: 0.8333\n",
      "Epoch 441/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1832 - accuracy: 0.9289 - val_loss: 0.3299 - val_accuracy: 0.8500\n",
      "Epoch 442/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1827 - accuracy: 0.9205 - val_loss: 0.3016 - val_accuracy: 0.8833\n",
      "Epoch 443/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1807 - accuracy: 0.9247 - val_loss: 0.3395 - val_accuracy: 0.8333\n",
      "Epoch 444/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1816 - accuracy: 0.9414 - val_loss: 0.3286 - val_accuracy: 0.8500\n",
      "Epoch 445/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1821 - accuracy: 0.9414 - val_loss: 0.3128 - val_accuracy: 0.8500\n",
      "Epoch 446/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1804 - accuracy: 0.9414 - val_loss: 0.3344 - val_accuracy: 0.8333\n",
      "Epoch 447/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1800 - accuracy: 0.9414 - val_loss: 0.3108 - val_accuracy: 0.8667\n",
      "Epoch 448/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1809 - accuracy: 0.9289 - val_loss: 0.3178 - val_accuracy: 0.8500\n",
      "Epoch 449/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1884 - accuracy: 0.9289 - val_loss: 0.3320 - val_accuracy: 0.8500\n",
      "Epoch 450/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2000 - accuracy: 0.9205 - val_loss: 0.2884 - val_accuracy: 0.8667\n",
      "Epoch 451/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1966 - accuracy: 0.9247 - val_loss: 0.4007 - val_accuracy: 0.8333\n",
      "Epoch 452/486\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1859 - accuracy: 0.9163 - val_loss: 0.2922 - val_accuracy: 0.8667\n",
      "Epoch 453/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1958 - accuracy: 0.9038 - val_loss: 0.3018 - val_accuracy: 0.8833\n",
      "Epoch 454/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1774 - accuracy: 0.9331 - val_loss: 0.3637 - val_accuracy: 0.8333\n",
      "Epoch 455/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1869 - accuracy: 0.9289 - val_loss: 0.3216 - val_accuracy: 0.8500\n",
      "Epoch 456/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1793 - accuracy: 0.9289 - val_loss: 0.2934 - val_accuracy: 0.8667\n",
      "Epoch 457/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1837 - accuracy: 0.9289 - val_loss: 0.3300 - val_accuracy: 0.8500\n",
      "Epoch 458/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1821 - accuracy: 0.9331 - val_loss: 0.3251 - val_accuracy: 0.8500\n",
      "Epoch 459/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1835 - accuracy: 0.9331 - val_loss: 0.3118 - val_accuracy: 0.8500\n",
      "Epoch 460/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1816 - accuracy: 0.9372 - val_loss: 0.3364 - val_accuracy: 0.8333\n",
      "Epoch 461/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1799 - accuracy: 0.9414 - val_loss: 0.3055 - val_accuracy: 0.8667\n",
      "Epoch 462/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1810 - accuracy: 0.9289 - val_loss: 0.3135 - val_accuracy: 0.8500\n",
      "Epoch 463/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1809 - accuracy: 0.9289 - val_loss: 0.3309 - val_accuracy: 0.8500\n",
      "Epoch 464/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1828 - accuracy: 0.9331 - val_loss: 0.3376 - val_accuracy: 0.8333\n",
      "Epoch 465/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1797 - accuracy: 0.9372 - val_loss: 0.3036 - val_accuracy: 0.8833\n",
      "Epoch 466/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1829 - accuracy: 0.9247 - val_loss: 0.3191 - val_accuracy: 0.8500\n",
      "Epoch 467/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1837 - accuracy: 0.9163 - val_loss: 0.3190 - val_accuracy: 0.8500\n",
      "Epoch 468/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1858 - accuracy: 0.9372 - val_loss: 0.3419 - val_accuracy: 0.8333\n",
      "Epoch 469/486\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1886 - accuracy: 0.9247 - val_loss: 0.2982 - val_accuracy: 0.8833\n",
      "Epoch 470/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1838 - accuracy: 0.9247 - val_loss: 0.3512 - val_accuracy: 0.8333\n",
      "Epoch 471/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1827 - accuracy: 0.9372 - val_loss: 0.3170 - val_accuracy: 0.8500\n",
      "Epoch 472/486\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1930 - accuracy: 0.9079 - val_loss: 0.2986 - val_accuracy: 0.8833\n",
      "Epoch 473/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1764 - accuracy: 0.9372 - val_loss: 0.3744 - val_accuracy: 0.8500\n",
      "Epoch 474/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1918 - accuracy: 0.9289 - val_loss: 0.3053 - val_accuracy: 0.8667\n",
      "Epoch 475/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1825 - accuracy: 0.9163 - val_loss: 0.3052 - val_accuracy: 0.8667\n",
      "Epoch 476/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1829 - accuracy: 0.9289 - val_loss: 0.3455 - val_accuracy: 0.8333\n",
      "Epoch 477/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1799 - accuracy: 0.9331 - val_loss: 0.3015 - val_accuracy: 0.8833\n",
      "Epoch 478/486\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1863 - accuracy: 0.9331 - val_loss: 0.3109 - val_accuracy: 0.8667\n",
      "Epoch 479/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1838 - accuracy: 0.9331 - val_loss: 0.3145 - val_accuracy: 0.8500\n",
      "Epoch 480/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1816 - accuracy: 0.9247 - val_loss: 0.3060 - val_accuracy: 0.8667\n",
      "Epoch 481/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1823 - accuracy: 0.9289 - val_loss: 0.3377 - val_accuracy: 0.8333\n",
      "Epoch 482/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1835 - accuracy: 0.9289 - val_loss: 0.3057 - val_accuracy: 0.8667\n",
      "Epoch 483/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1861 - accuracy: 0.9331 - val_loss: 0.3376 - val_accuracy: 0.8333\n",
      "Epoch 484/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1838 - accuracy: 0.9247 - val_loss: 0.2956 - val_accuracy: 0.8833\n",
      "Epoch 485/486\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1857 - accuracy: 0.9289 - val_loss: 0.3315 - val_accuracy: 0.8500\n",
      "Epoch 486/486\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2026 - accuracy: 0.9205 - val_loss: 0.3068 - val_accuracy: 0.8667\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(X_train, y_train, 16, 0.2, 0.01, 64, 486)\n",
    "plot_history\n",
    "val_loss = model.evaluate(X_valid, y_valid)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14119531,  0.04894771, -0.00521481,  0.00551603,  0.        ,\n",
       "        0.96954112,  0.19390822])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09627648,  0.0665183 , -0.0312461 ,  0.01985046,  0.00350096,\n",
       "        0.97676869,  0.17563165])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_train_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        32\n",
      "           1       0.94      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.92      0.93       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_binary = numpy.where(y_train_predict > 0.5, 1, 0)\n",
    "report = classification_report(y_binary, y_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
